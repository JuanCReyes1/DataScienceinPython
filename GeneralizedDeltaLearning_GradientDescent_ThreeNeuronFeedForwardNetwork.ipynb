{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneralizedDeltaLearning_GradientDescent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanCReyes1/DataScienceinPython/blob/master/GeneralizedDeltaLearning_GradientDescent_ThreeNeuronFeedForwardNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC-GkQdYSG6d",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks\n",
        "## The Delta Learning Rule and Backpropagation\n",
        "\n",
        "## Juan C. Reyes - Dalhousie University \n",
        "### Nov.28, 2019.\n",
        "### The following exercise is based on Stephen Lynch's Book: Dynamical Systems with Applications using Python.\n",
        "### Chapter 20: The Delta Learning Rule and Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLavv1fSRzhN",
        "colab_type": "text"
      },
      "source": [
        "A neural network can be thought of as a parallel information-processing system. They are used in a wide variety of fields for implementing associative memories for pattern and speech production and recognition. When we model certain neural networks, we often try to attribute certain functions in our brains in common with their network architecture. \n",
        "\n",
        "In the following notebook we will implement a neural network composed of *neurons* and *synaptic weights* which together will perform a series of complex computations through what is called a *learning process*. We will be performing such complex computations on the famous Boston housing dataset which is publicly available through the sklearn.datasets library. \n",
        "The goal of this learning process is to devise a neural network which will accurately *predict* the dataset's target characteristic: The median *value* of owner-occupied homes in Boston (column 14).\n",
        "\n",
        "Since we are viewing this document through Google Colab you may execute my code as you read along by holding shift+enter on each code 'chunk'. Just make sure to 'view' this file through the 'playground' option in the top left hand corner. This mode will let you edit my code and save your own version!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zpuNAhwehOR",
        "colab_type": "text"
      },
      "source": [
        "### Importing Data and Data Cleaning\n",
        "Before we create a neural network to help us with any prediction task we must make sure that the data it will be operating on is as clean as possible. For this it is necessary to complete some *data cleaning* prior to running our model and fitting parameters.\n",
        "\n",
        "We import the sklearn.datasets package which contains the load_boston function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HMM32KPwSru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZeyFQ7SJBl",
        "colab_type": "text"
      },
      "source": [
        "Load the Boston housing dataset with the load_boston function.\n",
        "We display the type of data generated from this operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHqYoMFwU0q",
        "colab_type": "code",
        "outputId": "655d0261-abb6-4930-ca44-20327803e0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "boston = load_boston()\n",
        "print(type(boston))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOzyk3iFTWk-",
        "colab_type": "text"
      },
      "source": [
        "A 'Bunch' is a subclass of the 'dict' datatype. It supports all methods a dictionary object does.\n",
        "Lets find out the keys for each Bunch object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCWYcXhlweon",
        "colab_type": "code",
        "outputId": "983bf8dc-2bfe-40eb-9629-be3397a58c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(boston.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW9oJ8PP4dlB",
        "colab_type": "text"
      },
      "source": [
        "With the given keys we may explore the data downloaded:\n",
        "The housing data is stored under 'boston.data':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3A36EUb4ma3",
        "colab_type": "code",
        "outputId": "96353ecf-b1df-4411-b337-9a356c22700b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(boston.data) #display the housing data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
            " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
            " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAdkbHzhUVvr",
        "colab_type": "text"
      },
      "source": [
        "We can display the dimensions of the housing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdtZA8aswg-P",
        "colab_type": "code",
        "outputId": "fc8b946a-0767-4e98-9ffe-783467e3b17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(boston.data.shape) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfSUv9NEWVvm",
        "colab_type": "text"
      },
      "source": [
        "The Boston housing dataset consists of 506 rows (observations) and 13 columns (attributes).\n",
        "The column names (attributes) are stored in boston.feature_names :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTOjGXU_wjyv",
        "colab_type": "code",
        "outputId": "8c833458-907f-4556-d79d-441b7e7023dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(boston.feature_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiMNrM1yWxG6",
        "colab_type": "text"
      },
      "source": [
        "Our dataset has a strange choice of column names, lets look into our dataset's documentation to learn more about the data. It is worthwhile to note that boston.data does not include our target column values. Hopefully a description of the dataset will reveal more information on the structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yk01XmlwqUw",
        "colab_type": "code",
        "outputId": "b962d154-c3e4-4dc8-988c-9a4eb93598cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "#description of the dataset\n",
        "print(boston.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVbSxZdOgfxS",
        "colab_type": "text"
      },
      "source": [
        "The documentation of the Boston housing dataset revealed a lot of information regarding our dataset!\n",
        "We confirm that the size of our dataset is 506 measurements with 13 (numerical and categorical) *attributes* of our data. Our data's *target* column is the median value of owner-occupied homes.\n",
        "\n",
        " Our aim for now is to use just three of these attributes (columns) and their corresponding data (506 rows) to *train* a *learning model* which will help predict the target column (median value of owner-occupied homes) of our dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIv3IVlvxCjs",
        "colab_type": "text"
      },
      "source": [
        "We will make some small adjustments to this dataset with Pandas. Mainly adding our target value to the dataset, and displaying a quick summary of statistics relevant to the dataset.\n",
        "\n",
        "Recall that pandas is an open source data analysis library with many useful functions for data cleaning and manipulation readily available for us.\n",
        "\n",
        "We will now inport Pandas into our notebook and convert boston.data which is a NumPy ndarray into a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVaRt6-CxOaY",
        "colab_type": "code",
        "outputId": "c594e255-b588-4c2c-d8f2-bcd9d5d33d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(boston.data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJk1l2XIw6RD",
        "colab_type": "code",
        "outputId": "3100a6f1-c0a4-42d3-e387-fcd40e42fcc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "bos = pd.DataFrame(boston.data) #convert boston.data into a Pandas dataframe\n",
        "type(bos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv5Vav4oxbwW",
        "colab_type": "text"
      },
      "source": [
        "We use the df.head() function to display the first 5 features of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QePd8_xtxOCg",
        "colab_type": "code",
        "outputId": "f54798d8-a0c6-4464-e0fc-33d8c3f1f752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "bos.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1     2    3      4   ...   8      9     10      11    12\n",
              "0  0.00632  18.0  2.31  0.0  0.538  ...  1.0  296.0  15.3  396.90  4.98\n",
              "1  0.02731   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  396.90  9.14\n",
              "2  0.02729   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  392.83  4.03\n",
              "3  0.03237   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  394.63  2.94\n",
              "4  0.06905   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  396.90  5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5cwRKPwxmdp",
        "colab_type": "text"
      },
      "source": [
        "Our dataset's columns have lost their name label and have been indexed from 0-12. This can be solved quickly with Pandas.\n",
        "\n",
        "Recall that our column names were imported as *feature names* from sklearn.datasets . Lets see what they are again: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSYsz_JSxSB_",
        "colab_type": "code",
        "outputId": "4b4863d1-ab19-4ac9-a53a-3a96e6f06daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#column names\n",
        "print(boston.feature_names)\n",
        "print(type(boston.feature_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-EJEey9yGRo",
        "colab_type": "text"
      },
      "source": [
        "Simply assign these feature names to the columns of our Pandas dataframe with the df.columns function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFEmXMiyS8y",
        "colab_type": "code",
        "outputId": "39654d91-f093-4d31-935c-aedc92d86349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "bos.columns = boston.feature_names #Assigns the feature names (numpy.ndarray) to the column names of our Pandas dataframe.\n",
        "print(bos.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
            "       'PTRATIO', 'B', 'LSTAT'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4a9iMxSzbys",
        "colab_type": "text"
      },
      "source": [
        "Reviewing our dataframe again should display our dataframe with the column names added to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT_714E8yUX7",
        "colab_type": "code",
        "outputId": "e6eb15d4-667d-4637-d583-a76466f68e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "bos.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQuWyqOy7p7",
        "colab_type": "text"
      },
      "source": [
        "The authors of the dataset have chosen to not include our target column into the dataset. As a result, there is no column named 'PRICE' in our Pandas dataframe.\n",
        "The target column is available as a separate attribute in the Boston bunch called 'target'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYaWtPBByV5t",
        "colab_type": "code",
        "outputId": "4102cfd7-28c1-4232-c7a0-8a3350c1d4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "#Check\n",
        "print(\"target shape: \" +\"\"+ str(boston.target.shape))\n",
        "print(boston.target) #our target column !"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target shape: (506,)\n",
            "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JFB4tffzLW3",
        "colab_type": "text"
      },
      "source": [
        "As we can see our target column exactly matches the number of rows (506) in our Pandas dataset. We will now add the target column to our Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTmfRUAny3pG",
        "colab_type": "code",
        "outputId": "08df3aa7-7fa1-4b63-ee61-76ba0d22bffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "bos['PRICE'] = boston.target # Add the boston.target rows to a new column in our dataframe 'PRICE' \n",
        "bos.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kkxtwa7zeL8",
        "colab_type": "text"
      },
      "source": [
        "Our data is officially clean! \n",
        "Lets perform a quick summary of relevant statistics for our data with the Pandas df.describe() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-szT1Ghe0f1E",
        "colab_type": "code",
        "outputId": "68c8275f-25e2-44e4-a122-aa9db8ba6093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "bos.describe() #provides summary statistics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>22.532806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>9.197104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>1.129600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.730000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>5.885500</td>\n",
              "      <td>45.025000</td>\n",
              "      <td>2.100175</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>375.377500</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>17.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.256510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>6.208500</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>3.207450</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>391.440000</td>\n",
              "      <td>11.360000</td>\n",
              "      <td>21.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.677083</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>6.623500</td>\n",
              "      <td>94.075000</td>\n",
              "      <td>5.188425</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>396.225000</td>\n",
              "      <td>16.955000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.976200</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>12.126500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>711.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>396.900000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             CRIM          ZN       INDUS  ...           B       LSTAT       PRICE\n",
              "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
              "mean     3.613524   11.363636   11.136779  ...  356.674032   12.653063   22.532806\n",
              "std      8.601545   23.322453    6.860353  ...   91.294864    7.141062    9.197104\n",
              "min      0.006320    0.000000    0.460000  ...    0.320000    1.730000    5.000000\n",
              "25%      0.082045    0.000000    5.190000  ...  375.377500    6.950000   17.025000\n",
              "50%      0.256510    0.000000    9.690000  ...  391.440000   11.360000   21.200000\n",
              "75%      3.677083   12.500000   18.100000  ...  396.225000   16.955000   25.000000\n",
              "max     88.976200  100.000000   27.740000  ...  396.900000   37.970000   50.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nErUQ5BeRXr6",
        "colab_type": "text"
      },
      "source": [
        "While it is handy to work with our dataset in Pandas to clean data, add column names, and obtain statistics, we will now return to working with our data as a numpy array in order to perform various numerical calculations using the NumPy package in Python.\n",
        "\n",
        "Import the NumPy library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoZwlpdISr-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAWtbTU92Yzi",
        "colab_type": "text"
      },
      "source": [
        "We can use the Pandas.DataFrame.to_numpy() function to convert a Pandas Dataframe to a NumPy ndarray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVdc-_uU0mM4",
        "colab_type": "code",
        "outputId": "33c5aed5-bb3b-4cb0-deac-38c0ac370dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "bosnp = pd.DataFrame.to_numpy(bos) #convert from Pandas dataframe to NumPy ndarray.\n",
        "print(type(bosnp)) #display the type of data generated\n",
        "bosnp #show data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 3.9690e+02, 4.9800e+00,\n",
              "        2.4000e+01],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 3.9690e+02, 9.1400e+00,\n",
              "        2.1600e+01],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 3.9283e+02, 4.0300e+00,\n",
              "        3.4700e+01],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 5.6400e+00,\n",
              "        2.3900e+01],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 3.9345e+02, 6.4800e+00,\n",
              "        2.2000e+01],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 7.8800e+00,\n",
              "        1.1900e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5FnscYL2tY2",
        "colab_type": "text"
      },
      "source": [
        "Lets confirm that the size of our dataset remained unchanged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9807xKCCSj00",
        "colab_type": "code",
        "outputId": "9d11babd-620b-4f83-f427-0a1ece56c390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "rows, columns = bosnp.shape #assign the dimensions of our dataset to variables\n",
        "print(rows)\n",
        "print(columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "506\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpxinTiOWJ-M",
        "colab_type": "text"
      },
      "source": [
        "# Implementing a Generalized Delta Learning Rule with Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFQNpVBdcphM",
        "colab_type": "text"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1wBP3Tq8qmGLPWUKD2ESj9ulhXGAiwEFY' alt = \"a neuron\" width=\"600\" height=\"400\" />\n",
        "<figcaption>A model of a single neuron with a bias $b$, inputs $x_{n}$, activation function $\\phi$, and output $y_{k}$</figcaption>\n",
        "</center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcKzMcFO93f",
        "colab_type": "text"
      },
      "source": [
        "Now that we have a clean dataset we can turn our focus to creating a neural network to help us with making a prediction process of our dataset. I present a Python program which applies the generalized delta learning rule to the Boston housing data for three attributes: average number of rooms, accessibility to radial highways, and percentage of lower status of the population to help us estimate the target value of owner-occupied homes in the Boston housing dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTZi1uhGdcIo",
        "colab_type": "text"
      },
      "source": [
        "Consider a single neuron as presented in Figure 20.1 Given a linear activation function then our output is given by:\n",
        "\n",
        "$ y_{k} = \\sum_{j} w_{kj}x_{j} + b_{k} $\n",
        "\n",
        "With an *error function* defined by the mean squared error:\n",
        "$E = \\frac{1}{2N} \\sum_{x} (E_{k}^{x})^{2} = \\frac{1}{2N} \\sum_{x} (t_{k} - y_{k})^2$\n",
        "\n",
        "Here the x index ranges over all input vectors, $N$ is the number of neurons in our model, $E^{x}$ is the error on vector $x$ and $t_{k}$ is the target output when vector x is presented. \n",
        "\n",
        "The aim is to minimize the error function $E$ with respect to the weights $w_{kj}$. This is an *unconstrained optimization* problem. Parameters $w_{kj}$ are sought to minimize the error. The *method of steepest descent* is applied to the error function to adjust the weights in our neural network.\n",
        "\n",
        "The method of gradient descent we will be using:\n",
        "The gradients $g = x_{k}(1- y_{k}^{2})(y_{k} - t_{k})$ to update each weight:\n",
        "$w_{kj}(n+1) = w_{kj}(n) - \\eta g_{kj} $.\n",
        "\n",
        "We begin our implementation:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApwwA8l4VvOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = 4 #Define the total number of inputs into our model (1 bias + 3 column attributes)\n",
        "X = bosnp[:, [5,8,12]] # cols(attributes): average num. rooms, access.to radial highways, percentage lower status of pop.\n",
        "t = bosnp[:, 13] #target column: median value of owner-occupied homes.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNyDdr1oWr1G",
        "colab_type": "text"
      },
      "source": [
        "Initialize our weight arrays and iteration count variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PinfRTDlWT6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ws1, ws2, ws3, ws4 = [], [], [], []\n",
        "k = 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "actP0qI1W_p3",
        "colab_type": "text"
      },
      "source": [
        "We scale our data to a mean of zero:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0uLNetfWUr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate the average\n",
        "xmean = X.mean(axis=0)\n",
        "#Calculate the standard deviation\n",
        "xstd = X.std(axis=0)\n",
        "\n",
        "#Create an array of ones, will help with algebra\n",
        "ones = np.array([np.ones(rows)])\n",
        "\n",
        "#Scale to zero mean\n",
        "X = (X- xmean*ones.T) / (xstd* ones.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI6gIkDhnNxq",
        "colab_type": "text"
      },
      "source": [
        "Incorporate a bias (+1) into our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2g1DaIWmenL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Incorporate our array of ones into our dataset as a bias input\n",
        "X = np.c_[np.ones(rows),X] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PP09ziFnqmB",
        "colab_type": "code",
        "outputId": "9d91cdcd-edf0-468e-9549-ddf6f24a5568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(X)\n",
        "print(\"X shape: \"+ \"\" + str(X.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          0.41367189 -0.98284286 -1.0755623 ]\n",
            " [ 1.          0.19427445 -0.8678825  -0.49243937]\n",
            " [ 1.          1.28271368 -0.8678825  -1.2087274 ]\n",
            " ...\n",
            " [ 1.          0.98496002 -0.98284286 -0.98304761]\n",
            " [ 1.          0.72567214 -0.98284286 -0.86530163]\n",
            " [ 1.         -0.36276709 -0.98284286 -0.66905833]]\n",
            "X shape: (506, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxzsW9jAbfin",
        "colab_type": "text"
      },
      "source": [
        "Additionally, scale the target variable to zero mean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39Zyhz6XgI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate the average of the target variable\n",
        "tmean = (max(t) + min(t)) / 2\n",
        "#Calculate the standard deviation of the target variable.\n",
        "tstd = (max(t) - min(t)) / 2\n",
        "\n",
        "#Scale to zero mean\n",
        "t = (t - tmean) / tstd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNz8lmDSiDnp",
        "colab_type": "text"
      },
      "source": [
        "Our data is labelled and scaled! We are now ready to implement the learning process. We begin by assigning small random weights to our weight vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSZXIWbXhCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = 0.1 * np.random.random(columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IToeJOCo4VZ",
        "colab_type": "text"
      },
      "source": [
        "Since the value of the weights have a direct impact on how each of the features are being taken into account and since we chosen the weights at random, **we are extremely likely to obtain a large error in our initial learning exercise**. We will see how the *gradient descent* method will yield an optimized set of parameters $w_{kj}$ such that they minimize the error from our predicted value $y_{k}$ and the correct target value $t_{k}$.\n",
        "\n",
        "We also fix our learning rate parameter $\\eta$ and introduce an epoch value, which corresponds to the number of times we wish to subject our dataset to the *learning process* to improve its accuracy.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxvCX2H3qBc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10 #number of iterations\n",
        "eta = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAvNCl8micch",
        "colab_type": "text"
      },
      "source": [
        "Calculate our first output vector with the random weights:\n",
        "We are using $\\phi (v) = tanh(v)$ as our activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To44ZLjdX0JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1 = np.tanh(X.dot(w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ6zfB1UjEzo",
        "colab_type": "text"
      },
      "source": [
        "Determine our error given the respective target variable t and our newly calculated output using our random weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDkmsz2vX01H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e1 = t - y1 #first error calculation\n",
        "mse = np.var(e1) #variance of our error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY_rfS67txxo",
        "colab_type": "text"
      },
      "source": [
        "Update our iteration count (we have performed one calculation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-aBEqfAjcEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgd0eZijSyX",
        "colab_type": "text"
      },
      "source": [
        "Now we iterate this same procedure over the total number of epochs we have chosen. At the end of all epochs we store all our weight values into an array where we can investigate to which values our parameters converged to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6VIaJqEt_W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for m in range(num_epochs): #number of calculations \n",
        "  for n in range(rows):\n",
        "    ## Calculate new output given the new weights and calculate the error.\n",
        "\n",
        "    yk = np.tanh(X[n,:].dot(w)) #new output vector given new weight vector\n",
        "    err = yk - t[n] #error recalculation step\n",
        "\n",
        "    ## Now use gradient descent to calculate new weights w for the next loop.\n",
        "    \n",
        "    g = X[n,:].T * ((1 - yk**2) * err) #first recalculate the new gradient vector g\n",
        "    w = w - eta * g #delta rule for a linear activation function\n",
        "    k += 1 #update our iteration parameter count\n",
        "\n",
        "    ##Append new weight values into our list of weight values \n",
        "    \n",
        "    ws1.append([k, np.array(w[0]).tolist()])\n",
        "    ws2.append([k, np.array(w[1]).tolist()])\n",
        "    ws3.append([k, np.array(w[2]).tolist()])\n",
        "    ws4.append([k, np.array(w[3]).tolist()])\n",
        "\n",
        "## Store our complete list of iteration counts-weight values as a NumPy array.\n",
        "ws1 = np.array(ws1)\n",
        "ws2 = np.array(ws2)\n",
        "ws3 = np.array(ws3)\n",
        "ws4 = np.array(ws4)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqHnjKE53vbj",
        "colab_type": "text"
      },
      "source": [
        "Our weight vectors $\\sum_{i=1} ^ {n=4} w_{i}$ are now stored as NumPy arrays. For each weight, we may now check the parameter value to which our gradient descent model converged to, given our number of epochs and learning parameter $\\eta$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azN_DlxM3VWT",
        "colab_type": "code",
        "outputId": "9847d3ea-a089-4b5c-f459-6eff38f22769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k #the total number of iterations our program performed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FUVY-XA6gpH",
        "colab_type": "code",
        "outputId": "797bd57d-aacd-43c6-a111-a374189627b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ws1f = ws1[k-2][1]\n",
        "ws2f = ws2[k-2][1]\n",
        "ws3f = ws3[k-2][1]\n",
        "ws4f = ws4[k-2][1]\n",
        "print(ws1f)\n",
        "print(ws2f)\n",
        "print(ws3f)\n",
        "print(ws4f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.2644246610778815\n",
            "0.21528347662655192\n",
            "-0.04513856184549004\n",
            "-0.21603947335808393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lyma3Uk7lWT",
        "colab_type": "text"
      },
      "source": [
        "From reading the last of our parameter values from our NumPy array's of weights we can see our weight values:\n",
        "\n",
        "\n",
        "1.   $w_{1} = w_{1f} = -0.27$ \n",
        "2.   $w_{2} = w_{2f} = 0.21$ \n",
        "3.   $w_{3} = w_{3f} = -0.04$ \n",
        "4.   $w_{4} = w_{4f} = -0.24$ \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCaAoszVBqKC",
        "colab_type": "text"
      },
      "source": [
        "It is much easier to visualize our weight values converging if we interpret this visually through a graph.\n",
        "We now import matplotlib to help us with creating mathematical graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6BiRdGj6lA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYRlGXy8CB4n",
        "colab_type": "text"
      },
      "source": [
        "We create our plot with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7xzkPGCAXT",
        "colab_type": "code",
        "outputId": "a1514866-e9ee-49ea-c468-ab6eb719b0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "## Plot our iteration number k vs weight value\n",
        "\n",
        "plt.plot(ws1[:,0], ws1[:,1], 'k.', markersize=0.1)\n",
        "plt.plot(ws2[:,0], ws2[:,1], 'g.', markersize=0.1)\n",
        "plt.plot(ws3[:,0], ws3[:,1], 'b.', markersize=0.1)\n",
        "plt.plot(ws4[:,0], ws4[:,1], 'r.', markersize=0.1)\n",
        "\n",
        "## Label our axes\n",
        "plt.xlabel('Number of iterations', fontsize=15)\n",
        "plt.ylabel('Weights', fontsize = 15)\n",
        "plt.title(\"Weight value convergence over number of iterations.\", fontsize=15)\n",
        "plt.tick_params(labelsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEiCAYAAACGKbfRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeXwURfqHn5oMIYQQQogxRsQIiIiK\nqIi3IJciKpeKgigKuqLuuur+vA/wWEVZXXVVlvXAC0XxWl0UAVERVBARBZQ7XCGEEEIIyRAm8/7+\nqJ5kMkySGXKT98mnP5Ouru6qru6ub711GhFBURRFURoLrrqOgKIoiqLUJip8iqIoSqNChU9RFEVp\nVKjwKYqiKI0KFT5FURSlUaHCpyiKojQq6pXwGWNGG2PEGNMmyH2C435VkHtfx/3MCMIYZ4zJPoC4\nTTHG/FSJn2jn+l0jvf6BYozp6aTB8bUVpqI0NIwxac53clFdxyUUxpjDjDEzjDG7nHj2LMdfujFm\nYsD+5caYUbUVz4BwQ+Z19T2d/dQr4QMWOL/BQnYmUFCO+15gcQRhvAycf0Cxq5xo4CGg1oRPUZSD\ngvuAE4ErgTOAn8vxNxh4LmD/cmBUjcYsNOXldVux8f+u1mMUAe66jkAQfwA5WEF7D8AY0wToBkwh\ntPAtFpG94QYgIpuBzdURWaXhYoxpJiKFdR2Pg4XGnp7VcP+dgB9FZEZFnkRkSRXCqBBjjAGaiojn\nQK/h5MU/VF+saggRqVcb8BmwMGC/O1AInAB4gRaOuwvIBZ4MOn8g8BPgATKBJ4EmAcfHAdlB53TB\nWpseYDlwoXONKQF+pjhufYFfgT3YUs1xAX4kxJYW4h6Pco4NCHKPcuL8qLPfCXgX2IS1eJcDfwVc\nAef0dK51vLOf5uxfFHTtKcBPQW7HA/8Ddjvb+0BKGM+oC/Cpk/75wEKgb9D9fQzkOdf9FOgQdA0B\nbgX+DmwHsoAXsB9e2GkUzn0EpNH5wH+dOL/iHGvlpPEeIAO4C5gIpAeF29bxl+M8i5nAMQHH/el+\nOfBvYBe2gDU+8HmFmX6JwGRgG/adXACcFsZzqTDdga+B90Oc9xSwETDOfgz2u9mErVFZClwYdE46\n8A/gAec+91UQr3QnTW9z/O500jIhwM8oJ/3iQp0bdA/TgWuB9U76vQk0xeYVCx23r4G2IZ7PcMf/\nbuw791CI+B7w+3SAzyU4z0ivLC0Dvungc8dFmhcCZwOLnGc9EmgO/AtYiX3X12O/zfjK8jpC5D/Y\nb3Yc9h3bi83HhofKn6ggf3X8jQZWYDUhG/gm2E84W60LWxgf771AEdDM2b/VSQAD7AD6OO4nOAk8\nMODcy4Fi4EWgHzAWm7kEfjjjCBA+IBZrni/BViNc6TzwLPYXvizgF2AYcAmwClhGaYZxnhOnR4DT\nna1pOff5I/B6kFsvyopYb2zGeTH2Y/srNkO9J8RHGJHwAR2ca83BfiBDnRdqkf9+yol3J+zH+xNw\nhfOi3gNc5xxvCqxz0nCYc91lwBYgMejD2ejE63zg/7AFmzsjTKNK7yMgjTY7z6YXcKZz7BPsezUG\nuMi5ziYCMh+sEG103pHLHX/fOf6aBaV7OlYQ+gJPOG6XR5h+PztpeDVwgRPH3VRQKAkn3bHfwx6g\necB5BthA2W/kM+y7Phb7Hb3sPJuuQRnwVmA29lsYUkHc0p30+wxbqLwBKxYvBvgZRfjCt9n5vQi4\nCZuZTsYK9AhgkBPeFwHn+Z/PFmzB5HzgMcAH3BzJd0EF79MBPpfTnWf+lfP/SZWkpV/42jvn/Exp\nftMmwrywAFgL/Ambfx0DHAK8BFwK9ACuAn4HZgacGzKvI7TwPQbsA+530n2y4+fKCPPXc53r3OM8\ng0uAx8tL+wp1JtITanpzElqAc539acBTzv//Ax50/v+T4++QoA/4taDrXYctHbQOeNiBwnczVmgP\nD3Dr7lw7WPi8wNEBboMcf52c/Thnf1QY93mb8yI2DXD7N7CsHP8GWzV9L7AuwL0nByZ8b2I/xugA\nt6OxH8uACuL9DvaDb1bO8RuddGoX4NbGSeNAwRbg26BzPwZ+iCSNwrmPgDR6Jii84x33ywLcmmFL\nkoHC9whWHAOFuxU2g7w5KN3fCArjF+DdCNJvtJNWge+ZG5s5PVXBc6k03bEZmhe4IsDPGU68uzn7\nvZ39HkHX/5YAa5FS4YsJ411Pd+LvDnD7J5AZsD+K8IUvF2gZ4PYeAXmG43aT4xYb9Hy+DLr+f7Ai\n5Krq+1TF7+FrYHqYaRmYHtOBr4P8RJIXCgHGQzlhuoGzHL9tHbeQeR1B+Q+20LiHIMsamAGsDNif\nQuX569+wTVth60l5W33r3AK2ZOWltD3vTOB75/8fgtxXi8h2Z78jtjrqPWOM279hS0Qx2EwuFKdi\nE3OL30FEFmKrmYJJF5HVAfsrnN82IfxWxntAPLZEjxPXIVihx3GLMcaMN8aswZZq92FLT0c5/qtC\nH+AjwBeQVuuxH1a3Cs7rBUyT8tszugM/i8g6v4PYdtX52CqVQL4M2l9B2bSsNI0ivI//Be37j38a\nENdCrBUTSB9gFpAXEMZubKeq4DAqu6fK0q+Pc931AWGBrdKp6LlUmu7Ot/IVtkTtZxiwVkT8PZb7\nYKvF5gd9R3NChD9Hwm8Pmisi3oD9FUCy04YfKT+JyK6A/TVYIfkuyA0gNejcj4L2P3T8+J9RVd6n\nUETyPVQXkeSFAnwefAFjzEhjzBJjTD423/GnbccI43I8tlbt/SD3aUBHY8whAW6V5a+/ACcZY54x\nxpxrjImOMC4l1DvhE5EC7A2e6QxraENpb8/vgdOdRtgzsS+PnyTndwb2Qfm39Y77EeUEmYJtYwom\nlFtu0H6R8xtTzrXLxRHa7yjNhHpj7+HdAG8TsKWcydgqolOBRw80zCCSsO1Z+4K2dpSfVgCtsSX9\n8jiM0IWGbdjSXyCh0rPkvsJMo0juIzheKcDuEJl38LNPcuIQHMZ5IcKo8J6oPP2SsNVGwWFdGyKs\nQMJN93eB/saYeGOMC7iMsgWJJGy6BIc/LkT4ocIrj1DpYrDVY5ES6lq7RcQX5Ab7fydZ5ewf5vxW\n5X0KRSTfQ3URSV64U0SKAvYxxgwG3sDmt5dh38fBzuFI8x1/ugangX8/MA0qzF9FZDb2OzgXayFn\nG2NeMMY0jzBO9a5Xp5/52Lr6M7GlgEzHfSHQAlvV0AHbWOsnx/m9AdsWE8z6EG5gS7fHhHA/JIRb\ndTMNeMIY0wybsS4JKvFcBjwvIiX3aYwZUMk1/Zl4cGmoVdB+DrZk+3KIa1Q0znEHpS9zKLYCx4Vw\nP5TSZxQJlaVRJPchQfuZQAtjTEyQ+AU/+xxsJ4ZHQoSxu5L4B1NZ+uVg2//GhjhWUe/lcNP9I2z7\nzUBsdVgqZYUvB1v1N6iCsPwEp2dVCPe9rSrJ5ez7CyNVeZ9CUd3fQzhEkheGuofLsD1Mb/I7GGN6\nHGBc/OmajH33/Rzq/EaUBiLyOvC6YykOAZ7BfoN3R3Kd+ip8C7CdWq6htJoTEckzxizHWkFQ1uJb\nif1g00TkPxGEtQgYbow53F/daYzpTumDiYRILcD3gWexpanB2IbaQJoRkNkZY6KwHSIqIgtbujs2\n4Lw4bCFiQ4C/OdgPcrE4FehhMge43BhzXznVXD8CVxtjjhKR9U74hzvhj4sgHD+VpdGB3gdYgQHb\nSO4fPtMM2+EkUNDmYDsLLK+gijJcKku/OdjOCBtFJNg6qYiw0l1EdhpjvsQWIjYAv4vIr0Hh3wHk\ni8gfEYRfVfxDjI7F+a6NMadhq7qrk8FY4fczBJs5+8OvyvsUiur+HoIJrlGAA88L/ZTJdxxGhAiX\nEGEHswzbgeYy4OEA98uBVQFNVRHhnPdvY8wQoHOk59dn4QPojxXAQL4Hrsd2if7d7ygiPmPMHcCb\nxph4bL11EbaKYhBwqVONGsxr2N5GnxljxmMf+nhsdZcvhP9yEZEiY8x6bMa2DFuK/TW4KiHAf5Yx\n5mtsV+8EnMw3gFnAzU4bXw62I06FVUNOOnwC3GaM2YCtPrgD26gdyDisBf0/Y8yr2NLs4dhMf4qI\nfF1OEOOxhYVvjTH/wJbiTgJ2iMir2Ebqu4DPjTEPYjsFPORc/98Vxb2c+6ksjQ70PhCRZcaYT4GX\njDEtsBbg7dgPNfDZP43t2faVMeZ5bKZyKLYj1nci8k4Et1RZ+r2B7RDxtTNDxzps9Wh3bGeQZ8q5\n7hTCT/dpwKvYzjn/Cjo2CztUY5YxZgK263k8dqByjIjcE8G9RsJCbLo+Z4x5AFsFdid2CEB1cpwx\n5t/AB9gqs9HArQHVpOM4wPepHKZQjd9DCP4ABhpjBmHFO0NEMg4wL/QzC3jBGHMfVrgvxDYzlFBe\nXhd8IRHJMcb8E7jfGOPFFjaHONe8MpIbdfLnRJxqTux304MAa8/JK78RkdEVXqw6esjUxIYtjZb0\nNgtwH+W4/6+c8/oD87A9ifKw7YWP4vQoI/Q4vhOxYrsXW1oahO1K+88AP1PYfxxcGvt33e2HfQE8\nlDOOL+gaYxx/34c4dii22iUPWyf+JFb0S3q/EdSrM+C8T5zzNmCrPELFvxO2V1gOVhjXYD/GNpXE\nuQu2/cA/zulHoHfA8XbYHpq7sd3WPyOgt5bjR4Bbgtz2ezaVpVE49xEqjQLOTcQKwR4njR/E9vT7\nJchfKraQtM15T9KBt3DGEIV6Fyp4bypLv5ZYK3cTNsPajO2EcVYlz6XSdHf8tcCKuxAwFjHgeFOs\nQPs7jWQCXxDQ25eg3oWVxGs/v4ToxYltw17kxG0JtidhmXMJ0fsx1HsT/MwDns8IbM/a3djC7XiC\nhu9U5X060OcS6r7CSUtse95HTlyFsuP4Is4LHfcobEEzyznvA+A0wsjrKH8c33hK3+cVwIgwvpMy\n16J0uNF2J8yVWNEzQekzpbJ09I+PUAIwxhyFFb4bROS1uo6PUns4vd+WYds4rqnr+CiKUv3U16rO\nWsUYcw921o4N2G7A92BLFR/UZbyUmscYcxnWmvsNW6V3PXbc1tV1GS9FUWoOFT6LYOvdU7HVWPOA\nv4lIdbcvKPWPPdgu0h2wVTK/AReLHcupKMpBiFZ1KoqiKI2KejeAXVEURVFqEq3qLIekpCRJS0ur\n62goiqI0KBYvXpwtIrUxAcgBo8JXDmlpafz0U4ULriuKoihBOOOH6zVa1akoiqI0KlT4FEVRlEaF\nCp+iKIrSqFDhUxRFURoVKnyKoihKo0KFT1EURWlUqPApiqIojQoVPkVRlBrEJz58EtHSntVGdkE2\nWXvsesZZe7LqLB71DR3ArihKoyCnMIdcTy4u4yoRgOTmycRFx9VYmD7x8U36N/jEx5EJR+IyLlzG\nhdvlpk18mxoLF2DVjlUMemMQPpePif0ncs+se3ig5wNcePSFNXrPDQEVPkVRag2vz8vmvM0lwuMy\nttIpLSGtRsNdlrWMK9+8kmX5yzAYBKEZzbik8yW8PPDlGhOCFdtXcP4b5yMIXrwAuHGT2DSRxTct\nrjHxy8zPZOR7Izks9jCiXdEMnzack+NPZsxHY7jy+Ct5ZsAzxDaJrZGwGwIqfIrSCMkvyienMAe3\ny43H6yHGHUN80/gatQQK9hXw3A/P8cBXD5SIgAsXLZu05KexP9GuVbtqD9Pj9ZBdkM35r53P8Ycc\nz5sj3iQhJqGk+jG7ILvaBSBvb16JwD+94Gl+Hvsz8U3j8frsPXt9Xj5f/Tkx7phqD7eouIicwhym\nLZvGoc0P5cVBL5IQk0B2QTZJsUlk7M7gs5Wf4XY17qy/cd+9ojRCMvMzGTt9LDM3zCSKKAooINGd\nSN+OfZk8cHKNiF92QTbP//A8kxZNYs6oOWUsnQ25G9hTtAef+EoswKqSX5TPxl0beWfpO5x6xKlc\n3fVqbjv7NpKbJ5f4KdhXwKSFk2jbsi0x7hjiouOIjoquUrhrctZwy4e3sCFnA2sL19IhoQMp56eQ\nFJtUxl9is0TGfDCGh/s9TFx0XEn1a5v4NgcUh815mxkzfQwrt65ks3cziU0TmTt6bkk6+59pcvNk\n5qyfQ8+jepLYLLHE8vZXvVZX+td3VPgUpQ7ZnLeZlLgU3C43G3dtJLZJ7H6ZZHWSX5TPXz75C2vz\n1vLE+U/gKfbQr30/3v/tfZJbJFc54w8mY3cGWXuyuPd/99KyRUvmXjeXzod0LuMnJS6FR+c+ytUn\nX010VDQJMQkkNks84DA3523mpuk38fmmz2lOc1zRLhZcv6CM6IGtZm3qasrQKUPxNfFxwTEXcOUJ\nVxLjjsEnPmKbxJIQkxCWZebxevgl8xdGThtJbHQshyQcwtsj36Zty7blPs/lW5fTdVJXBMFgaO5q\nzs2n3sx1p16H2+UuESF/gcAnPuKi40iISSjznJZlLeP//vd/rM9ZT6e2nfik3yckNksMWY2aEJPA\nI70e4dTJpyLOH0Drpq15pv8znHHEGcQ2iSW1RWrY6d0Q0YVoy6Fbt26iqzMoNcnCLQsZPHUwt591\nOyemnMilb15Km6Q2zL5mNilxKdUWjtfnLakCy9idwY0f38jUYVPpkNgBn/iIjoomb28eb//6NkM7\nDyUhJqGkA0ZVwly4ZSEDXh3AHvaQFp9Gx9YdmTpsKvFN48v4zczPpOszXcnyZdGEJnRJ7sJLA18i\nsVliSYafEpdCbJPYkh6K+UX5xLhj9sugV2xfwQ3Tb2D73u28funrpCWk4fF6ym1DzNidwaC3BhG9\nL5qfd/5MIYUYDC5cpMSkMKzzMEafPprYJrFl2iUD/y/YV8B/5v+H/yz9D73SevGvQf8ivmk8CTEJ\nFaZRdkE2+UX5JcK2cddGBkyx6SUILlwl4mQwRBHF4c0O55pu13BlFyvQ6bnpDH5jMO0S2/HOle+Q\nEpeyX/qGYt3OdSX34RMfCzYtYPTHo/Hh4/C4w/nhhh8OWPyMMYtFpNsBnVxLNAjhM8Z0Bp4HzgBy\ngZeB8SJSXME5pwI3AecAqcAmYCowQUQ8lYWpwqfUJBt3beScl8/hkrRLeG3Za0S5o3i0z6PMXjWb\nq0+5moGdBlZLO4zX52Xqb1OZ/ctspqdPp4m7CS8PepmhnYeWqdbyeD08+vWjzFs7j76d+pLaIpWz\njzyb6KhofOIraf8Ltn6Kiov2sxLzi/J5YeELTPh2AjeeciNXn3I1SbFJREdFl5spZ+Zn4vF6yPXk\nctsHt/F19tcAGAzNaMbgjoMZc8YYrnv/OgoLCskii0NjDmX68OklhYTM/EwufftS2rduzytDXqFj\n645hpZG/rdPfRuYyLvKL8nl67tN8uvJTsiW7pEOMP06B/zelKeceeS4TLphAh8QOVaoq3py3Ga/P\nWyKs63eu58iEI0viN27mOOasn0MeeRgMcVFx3N3jbsacPGY/izYSfOJj466N+MQXskARCSp81YAx\nphWwHFgBTADaA/8AnhGR+ys4byLQHXgTWA10AR4BZovI0MrCVeFTagKvz8u6nev4ftP3/J75O/ee\nd29JhpuWkEZOYQ5vLn2Tm7vfjNfnrVLHi7y9eazYvoIhrw+habOm3HrmrVx49IV0SOwQsi0nY3cG\nF75yIat2rUIQPHgwGNy4ObL5kQw6dhDXdr+WGHcMLuPC4/Xw5dov6de+H9FR0SXWz+QFk3lv5Xs8\ndcFTDO08NOJOHHl788guyAasRZWxO4MhU4awR/ZwbptzOSLpCMZ0G8MbP77Bi7++SDG2/Bvviuea\n46/h3r73VovFXLCvgLy9eRTsK9jPygv8P78on1cXvcqj/R6t9o4ywe2e+UX55O3Nw+P1lMSjbcu2\n9aqzigpfNWCMuQe4EzhSRPIctzuBcUCK3y3EeUkikh3kdgPwbyBNRCpcLFGFr/EQnNH6LZzqbmtL\nz01n6q9TeWjuQ7SOac13139Hh8QOZfzkFOYwcOpAHu/7OO8sfYexp40lLjquJAOMbxpf0v7lj7c/\nY0yIScDr85IUm0Te3jwue/0yfsz+kZu73cyfTvsTqS1SK80gcwpzKNhXAFBi/eR6crnzsztZsmUJ\n2dh0Ms5fU5pSSGEZt0NjDuXjqz6mW2q3auss4bcIk2KTcBkXsU1i8Xg9ZOZnlhGhlLiUau8tGQ4F\n+woa9fCAQBqC8NWfYkL59AdmBgncu1jrrwfwaaiTgkXPYYnzmwrU+1WClZonPTed6969jrnb5gKU\nWDjHtD6GudfNrTbx+3bDt1w85WKio6OZdc0sOiR2CNn5IC46jh5H9qDva32JJpoXf36xzLizTsmd\nmDxwMtFR0dz64a18nfU1Llw0pSmdW3fGi5fJg23PzGNSjuGZwc/QIbFD2J1WEpslhuxYMn3kdAr2\nFZSIor+AEOOOweP17OdW3Z0jQllwMe6YGh//Fy4qeg2LhiB8nYCvAh1EZKMxpsA5FlL4yuEMwAes\nrb7oKQ2VnMIchk0dhhhh0fWLSjpTeLweZq6ZWWIdVaWbvdfn5dsN3zJ06lDu6X0Plx93eYXj1aKj\nonnwvAcZ020MMe6YMtVseXvzuP6d6zn1P6cSQwxHtTyKH8f8SFJsEr9t+42JcyfiK/Zx2sun0cK0\nYNjxw0hLSKuWnprxTePD6jShKA2BhiB8rbAdWoLZ6RwLC2NMCnA/8KaIZJXj5wbgBoC2bdtGHlOl\nQeBvu8kuyKb74d2567y7ylhfRcVFuF1u7p1xLzeedSM7CnZwRMsjSqrYYpvE4na5iW0SS97ePHIK\nc8p0OQdr/RQVF/Hhig95esHTfDD8A8498tyw2mKio6LLtWRmjZ1FTmEOLuMiLjquxCJNS0ijR1oP\nXMZVUv2Z3DxZLRFFCUFDEL4qY4yJBt4D8oHbyvMnIpOByWDb+GondkptsjlvMw/89wE+W/cZHpeH\nO8+5c7/ecNFR0Vx8zMU8/MXDvPTbS7hx48VLFFEkuZM4Lvk4jk46mqu7Xc39/7ufr7d9XdLlPLjn\nX+vo1nw4/EPOPfLcaol/QkxCyG7yLuMqcVfLTFEqpiEI306gZQj3Vs6xCjHGGOAN4DjgLBGp9Byl\nbsjMzwQo046U2iK12gZVr9qxiivevoKdRTu5+qSrGX366HLbv9q2bMvS25dSsK8At8uN1+fF4/Xw\n2sLX+O/v/2X51uW8+uurtG/ZnoXXLywz5swfd5/4cLvctG2ptQeKUp9oCML3B7YtrwRjzBFArHOs\nMv4JDAT6ikg4/pU6YFnWMi545QIKigrY6ZRnWka15L6e93HrGbdWWfxW7VjFpVMv5fAWh/PuJe+W\nTFNVEaE6VDxy/iPcdd5d+MRHflF+jfT+VBSlZmkIwvc58H/GmBYisttxGwYUAt9UdKIzFOIW4HIR\n+a5mo6kcKNkF2Yx8fyR90vqQkpTC1V2vLpk2annW8og6lni8HjJ2Z5DcPLlkvFOuJ5exH4/l8LjD\n+c/Q/1RpRvwYd0yJYFZlwLCiKHVHQxC+ScBfgA+NMROAdtgxfE8HDnEwxqwBvhGR0c7+cODvwBRg\nizHm9IBrrhWR7bUTfaUyfOLj+KTjefKiJ4lvGl8iLB6vhzeWvMGJKSfuV4Xon9jXXwXpEx8er4dJ\n8ybx6m+vckbqGSzMWEgeecQSy4nJJ/LvIf+u8TXQFEWp/9R74RORncaY3sC/sEMXcoFnsOIXiBuI\nCtjv5/yOcrZArsUKolKHFBUXsWrHKib/NJmbz7q5ZHCyH4/Xwzerv+Gl714qM3A6iigOjT6UmKgY\ndhTuYBe7EMTOZdj8cKZeMZX7v7ifMaeOYfSpo0smG65s7kRFURoH9X7mlrpCZ26pWTLzM/nnd//k\nmR+f4YgWR/DdDd+FbFPLzM/k+e+fZ0TXESVTZeUX5fP8vOfZsGsDbZPa8tcz/lpiJcY2iSUlLoXs\nguyQc0sqilKzNISZW1T4ykGFr+bYuGsjA6cMJNubzTuXvUPH1h0rbC/zL5QaSMG+Arw+b8l4OkVR\n6gcNQfjqfVWncnCxJmcN9828j5axLXl70Nv7rc0WilBWm4qdoigHigqfUmtk5mdy3uTzaBbdjM+u\n+SzsZWMURVGqk8axzrxSL8jbm8fIk0cye/RsFT1FUeoMtfiUcvGPifN3GAmXjN0ZZdYLcxkX6bnp\nDH9/OF9f97XOZKIoSp2iwqeUoai4iM15m0vGxE36bRJt4tuw4PoFpMSl4PV5KSouKulhGUjG7gzS\nc9MZ8OoAcsktma/Sv1L0PT3uqXBlAkVRlNpAhU8pweP1MG72OCb8OKFkTNxX136FT3wkNkskMz+T\nT1d+yi9bfmHAsQPolGRnknMZF5vzNnPJa5dQHFXMNV2u4cazbyS2SWyZVQvq20rRiqI0TjQXUgA7\ne8rX6V/z7vJ3mXftPFJbpBLbJJbEZom8/evbLNm6hBe+e4Fte7bhwsWkJZMQ589giDWxjOoyilvO\nuYW0hDQdP6coSr1FhU8B7Li46cum8+WoL/freNK3fV96Te5Fu8R2fHzNxyQ2SyxZdTvQokttkaqC\npyhKvUeFT6GouIisPVk0dzcPOZdlUmwSw08Zzk3db9KJmRVFafDocIZGTlFxEY/Pe5w+r/UhNjo2\n5EoIMe4Y7j7nbhU9RVEOClT4Gjl/ZP/BN2u/4dJOl3LZCZeVu+6dVmEqinKwoMLXiNm4ayO9Xu5F\nYkwid/a8k64pXSNa+05RFKUhom18jRi3y83EARMZ1GmQLtmjKEqjQYv3jZR1O9fR/83+9GvfT0VP\nUZRGhQpfIyQzP5P7Z93PGSlnqOgpitLo0KrORkZ+UT5/++xv/Jz5M1+M+kKX91EUpdGhwtfIiG0S\ny41n3kiHxA4RTTytKIpysKBVnY2MFdtX8NwPz6mlpyhKo0WFrxFQsK+A9Nx0vk7/mt6v9uaE5BN0\nXJ6iKI0Wreo8SCnYV0DWnizyi/KZMHsC76x+h+bu5jx30XMMO25YuQPVFUVRDnZU+A5C0nPTeWDG\nA7yz+h0AUmNT+W70dyQ3TyYtIU0HqSuK0qhR4TuI8Hg9/LrtV654+wokSkrELtIV1BVFUQ5mVPga\nKD7xkbc3r2SR2FxPLvd/ej9v/vEm57U9j4kXT6RDYoe6jqaiKEq9Q4WvAeITHzNWz2DCnAnslb08\nfdHTfPjLh3y26TM+H/U5XTe7fW0AACAASURBVA7tQlx0XF1HU1EUpV6iwtcAWZOzhmvfu5ajWh1F\nUVERPV/ryeHND+ejER9x8mEn13X0FEVR6jUqfA2Mgn0FvLTwJf7e/+8MPnYwbpebnMIcbcdTFEUJ\nkwbRvc8Y09kYM8cYU2CMyTDGPGyMiarknGhjzFPGmHnGmEJjjNRWfGuSouIiduzZwWXHXUZSbBIJ\nMQm0a9VORU9RFCVM6r3wGWNaAbMBAQYCDwN3AOMrOTUWGAMUAAtqMo61hdfnZc66OUSZKNwuNdYV\nRVEOhIaQe94INAOGiEgeMMsYEw+MM8Y86bjth4jkGmMSRUSMMbcAvWoxztVOdkE2bpebXE8u/7jw\nH9p5RVEU5QCp9xYf0B+YGSRw72LFsEdFJ4pIg6/eTM9NZ+GWhfR5rQ93zbiLhJgE4pvG13W0FEVR\nGiwNweLrBHwV6CAiG40xBc6xT+skVjVMdkE2y7KW0ff1vjShCecefi5bCrZQsK+grqOmKIrSoGkI\nwtcKyA3hvtM5Vm0YY24AbgBo27ZtdV46IrILsjn7hbPJKs7i5YEvc1bbs4hvGs/4WeP55I9PGNhp\noFp9iqIoB0hDEL5aQ0QmA5MBunXrVmfVpInNEnnx0hdJS0grM7fmUwOewuvzqugpiqJUgYbQxrcT\naBnCvZVz7KBjc95mpv02jeTmyWUmlI5tEquipyiKUkUagsX3B7YtrwRjzBHY4Qp/1EmMapCcwhyu\n/uhq3hj8hvbcVBRFqQEagsX3OXC+MaZFgNswoBD4pm6iVHPERcdxcceLdUC6oihKDdEQhG8SsBf4\n0BjTx+mAMg54OnCIgzFmjTHmlcATjTH9jTGXAl2d/Uud7cgajbHXe+CnahueoihKjVLvhU9EdgK9\ngSjs0IXxwDPAQ0Fe3Y6fQF4C3gdGO/vvO9t5NRVfvF6YMeOAxM/r8zJvwzxSW6TqYrGKoig1RENo\n40NEVlDJzCsikhaOW43j8cCnn0KnTtCxY0SnuoyLFk1b0C21m05JpiiKUkOoWVHdxMRA9+7Qty+s\nWRPRqSu2r2Dsp2PJ9YQatqgoiqJUByp81Y3bDVdeCcOHwwsvQEHomVby88HnK93P2pPFle9fydju\nY0lsllhLkVUURWl8qPDVBHFxcNdd9tfj2e9wfj7cdJNtCsxzuufERcdx8dEXc1WXq7SaU1EUpQZR\n4aspXC5Ytgzuvtv+pqdbxQMyMmDOHBg5EkaNgrzdPjbkbuCstLOIcceUe8lAC1FRFEU5MFT4aor4\neJgwAT75BE44wW5XXUXOgj/4y19g7lwrfps2war0fLYXbKdv+77lWns5ObB8uYqfoihKVVHhq0k6\ndoSlS2HtWpgzB++SX2jSvyettq4gORm6doV7H9pDr0vW03Pi7fzwW1agYVjCihVw2WUwefL+xxRF\nUZTIUOGrYbJcKayjHeuSuvP2Dd8xIe9mXki8jwRXHi4XnHNGM1JbHoG8MJ8eJ7XxG4ZkZNihgN99\nB336wN690KoVzJtXpfHxiqIojR4Vvhpk2TI45RRo3x6OPhr+OrEN8ffdTHzblrYNEEhMhBffSWft\n2iZ+w5Dff7dtf+PHw4ABMGQIvPwyLFoUsq+MoiiKEgHafbCG2LzZVk+edhr873+2yQ+gTUo87llD\nIToagLy9eUxe9iSTL5lMfNN42rWDjz6CwYNtm96nn9phgTEx8PbbsGVLiWYqiqIoB4AKXw1QVATT\npkGvXvDQQ5CcHHDQ54IOHWD9enwd2rNu5zqGHT+M2CaxJV46d4b5861116ZN6alxcfDTT3DMMSW6\nqSiKokSI2g41wLp18M47dihfGdEDa64dfTR4vRTsK+BfP/6L8446b7/enElJZUXPf2pyslp8iqIo\nVUGz0GomO9t2TundO4To+fH5YMYMsnMzKPYW64B1RVGUWkRz3GomKQm++MJWS8aUNxY9J4e9kydz\n74YXaHfR8LCFz+eDrCxblerWJ6coinJAhG3xGWOSjTFHBewbY8wNxph/GmMurpnoNUySkioQPYCU\nFMxXs+jT/TLu7HFnhbO1BOJ2Q7duOqRBURSlKkRS1TkFuC1g/2HgReAC4CNjzKjqi9bBjzspmQt+\n20NcXvjjE1wu27FFZ29RFEU5cCIRvpOBrwCMMS7gRuBeEekEPAb8tfqjd/Diyc0mfsZsuG506UzV\nYaAdWxRFUapGJNloS2CH8/8pQCLwtrP/FdChGuN1UOPxepi4cgrpr0y04xIirLdU8VMURTlwIslC\nNwOdnf8HAH+IyBZnvyWgc4qEicfrYf6G+aQe2x1X3752upYwxc/lssMcVPwURVEOjEiyz1eBJ40x\n7wN3ApMDjp0O/F6dETuYcbvcnHbEacQ2T4DLL4fp08tdsDYYn8/OCqPtfIqiKAdG2J3iReRxY8wW\n4FTgz1gh9JMIvFzNcTso8fq8zFg9g6GdhxIdFQ0JCTBokF13yD+vWSUUFVkDUYc0KIqiRE4kwxna\nAu+IyJ9F5BURkYDDfwbmVnvsDkJWbF/BA7Mf4JDmh+AyLjsv2X//C2eeaRerrQSv105+/cUXOqRB\nURTlQIikqnM9cFI5x7o4x5UK+HXbrwx/fzi3nnkryc2daV3i4uCll+Cpp2xb38aNFV4jJgbGjrUr\nOKjwKYqiRE4klWWmgmMxwN4qxuWgJj03nUFvDeKk5JMYfkLQbC0JCXDGGXDiifb/efMgLa3ca8XF\n2QXdtapTURQlcirMOo0xXYCuAU4XGmM6BXmLAS4HVlVz3A4KCvYVkJ6bzltL3uL8o85n/PnjSYhJ\n2N9ju3awZAl8/LGd4fqOOypcgiEqqgYjrSiKchBTmc0wGHjI+V+AB8vxtx74U3VF6mChYF8BN02/\niamrpnJY88OYO3puaRVnKDp0sL08+/Sxi/l1cIZGejyQmWk7vyQmAlrNqSiKcqBU1sb3d6AFEI+t\n6uzl7AduTUWkvYjMrsmINkTSc9NZnb+aBdcv4Mcbf6Rdq3aVn5SaCvfeC+PG2V4sK1bAnXfC8cdD\n//6Qk4PXa52Limr8FhRFUQ46KrT4RGQfsM/Z1SHTEbAmZw0D3x7IyJNG0uXQLnboQji43dCvHzz4\nIEydCsbAoYfCjBmwbRvExxPtggEDYMMGO3enDmZXFEUJn4izTGNMR2NML2PMhcFbTUTQCbOzMWaO\nMabAGJNhjHnYGFNpK5cxpqUx5jVjzE5jzC5jzNvGmNY1FU8/uZ5cHprzEEM6DuGvp/81fNHzk5pq\nl1pftw5Wr7b/n3465OaCz4fLBR072tEPOpBdURQlMsLuF2iM6Qy8CxxH6B6eAlR7lwtjTCtgNrAC\nGAi0B/6BFe37Kzn9PaAjMAbwAROAj4Fzqjuefrw+L9NXTGdJxhIeH/U48U3DG5S+H8Gr2PoX4Ssq\nKun0ojO4KIqiRE4kHeL/DTQFhmBFqLZamG4EmgFDRCQPmGWMiQfGGWOedNz2wxhzBtAP6CEi3zpu\nW4AfjTF9aqpNMr8onw9++4CPr/qYti3bVt+Fo6Nth5fp02H4cCBCK1JRFEUBIqvqPAm4Q0Q+EZHV\nIrIheKuhOPYHZgYJ3LtYMexRyXnb/KIHICILsT1Q+9dERAFiiOGk9JNIjqqg9+YBXzwGWrcGlwuX\nC1JSaq99z6NTkCuKcpAQSba5Fjtmr7bpBPwR6CAiG4EC51jY5zn8Xsl5VcLr9bJ57WYmTpyIp7rV\nwueD7Gzw+fD5ICurdoY1eDzwj3+o+CmKcnAQifDdAdxrjAmjT3610grIDeG+0zlWbecZY24wxvxk\njPlp+/btEUcUIC4ujieeeIIVK1ZQVN3jDdxu6NYN3G5cLtsHZvXqmm/nC9BbRVGUBk9lM7cswnZa\n8XM48IcxJp0QoiIi3as1drWMiEzGWW6pW7duUon3cklISODII4/EW93mmM9nB7Ifeyxut4sePewk\nL8ccU+EkL2XIyLCWW0yMFc7KyM6G/Hw7sYwOmlcU5WCgMotvedA2A7vq+vwQx5bXUBx3Yhe6DaaV\nc6y6z6syMTExjBgxgmeffZaCMNfZCwuXy/b2dBr23O7IxOjnn+G44+Doo63huGBBxf5XrICzz7bT\niP76K0ycqNWdiqI0fCobwD6qluJREX8Q1CZnjDkCiCV0G17geaGGLXTCDmmoMVwuFx06dGDp0qX8\n8MMP9OzZE1eEvVDy8/OJi4sr61hUBLNmwRFHlExdFg4ZGXbRh5Ej4ZZbYOhQePVVGDgQpk2z82G7\nXNag9FuOmzfDqFE2qGuvhREj7Jh6tfoURWnoNIQ5Pz4HzjfGtAhwGwYUAt9Ucl6KMeZsv4MxphvQ\nzjlWo0RHR3PYYYdx33338euvvwKEXfWZn5/PzTffzLJly8jNDahRjomB666DJ58Ma8X27Gz47js7\n21m/ftZyu+MO6NrVXmLaNDstaPv2tiqzQwc7MP7oo6F3bzj1VHjzTbjtNmtodusWfpWqoihKfSWS\nAeyvVnDYB+QBvwAfikh+VSMWwCTgL8CHxpgJWOEaBzwdOMTBGLMG+EZERgOIyPfGmC+BN4wxf6N0\nAPt3tTGvaGxsLA899BAjRoygb9++TJs2jS1btnDllVfirmQ9oc2bN7N8+XJOO+00TjzxRKZPn06q\nv0EuIQGuuMKKoLMKu8dTVpA8Hls1OWIEbN1qLbdbboG2bSE21vqJiYFevWDNGrvvclmD8scfrXU4\ndGhZ/0VF0LRpmfHziqIoDRMRCWsDFgGZWAHZCvzq/Poc95XYQe2bgI7hXjfMsDsDX2GtvK3AI0BU\nkJ90YEqQWwLwGrYjTh4wFUgKJ8xTTjlFqoMdO3bI448/LtHR0XLIIYfI0qVLy/W7fft22bRpk3To\n0EEeeeQR+f777+X000+XMWPGyO7du62nfftEvvhCZN8+KS4W+flnkfvuEykstIcLC0X+/GeR5s1F\nLrlEZOnS0mPhsG+fyN69+7sXF4v88ovIxImhjyuKooiIAD9JNeb/NbFFIj79se1mpwa5d3dE7xLg\nKOysLp/U9Y1Vdasu4RMR2bdvn6xfv16WLl0qvXv3lp07d5Y5vmvXLtmyZYucfPLJ8swzz8jNN99c\n4mf58uXSsWNH+eCDD2TXrl1WmWbMsL8ism2byCmniGzdKrJnj8j334t06CAyf76IXyuri61bRY4/\n3v4qiqKEoiEIXyRTlj0JPCQii4IsxoXGmHHABBE51hjzBPBsBNc96HG73aSlpZGbm0tUVBT5+fkk\nJNjFaPPy8hg1ahTHHnssLVq0YMKECXzzzTclxzt37sw777zDxRdfzJlnnsm/X3iBxIC2woQEuOYa\n+OAD20tz5kx44QU7p3V1z+qSlAQPPQRbtpTpXFqj+IdeKIqiVBeRZF0dsFWNoSgA0pz/N2Dn9FSC\niI+P5/777+eBBx4gP982g3q9XkSEt956i0mTJrFo0SI6duxY5rwuXbpw3333sWrVKl5/5RWKfvsN\n8mzzZnQ0XHwxjB9vhe+zz+yUnjUhSm637Qzz0kth9a2pMh4P/POfdhyhoihKdRFJ9rgEeMgYkxLo\naIw5DLtK+2LH6Uggo3qid3Dhcrk48cQT8TlToBQVFfHWW29xwgknMHfuXDp16kSbNm32O8/tdjNm\nzBief/55du/di/ToAU88UaI+bdvCRx/B/Pk1Y+kFEhtre4XWRgcXlwtatoRPP9VhFIqiVB+RVHXe\nCMwE0o0xi4HtwCHAKUAOcL7jLxX4T3VG8mAiOjqaY445Bq/XS2ZmJt9++y0vvvgiycHLEIU4r3v3\n7ixbtgxz4ol2bT5HfVwuO1ShNqoefT7YudMKUU2Ln8sF8fHwr3/BeefZSbkVRVGqSthZpYj8ih1K\ncAewCluduQq4HWgvIr85/p4QkQk1ENeDgpiYGG666SYeffRRLrroIlq1arX/QPUK2LlzJx6v1843\nFqB0tbVKg8sFhx0GK1dGNndnTo5dVzc93Q6JqAyPxw6rOOIIOPlk+PDD8M6rTmo7PEVRaoeIsksR\nKRSRF0TkWhHp7/y+KCLltf0pIXC5XKxcuZILL7yQ/v37Ex2m6eR2uznhhBOY9vrrFL3xRp3MHxYd\nDZdfDp98Ep4w5ObaqdJ69LAD5bt2tR1ksrJK/QQLaHo63Hmn9fvUU3bQ/ebNtdvWV1QEr72m4qcc\nfOg73TBmbjnocLlcJCUlccUVV3DRRRdVOqDdj9vtpk+fPvjArstXR2+wywUbNlTc7pafD7/8Auef\nD+ecAy1awOLFtvPNyy/D4MH2+Jo1MG+e/V23Dn74Ac46y1p4X3wBb78NcXH2/wceqJ1ONWCTdv58\nO/tNbaMZU+1SV6uO1Na7HEhRkZ3YvrGvtlKh8BljsowxJzn/b3f2y91qJ8oNn7i4OJ5//nm6desW\ntrXnx+122/79N9wAzz5bJ1af2w1HHRX6WGZm6awxZ51lP7R582DGDFtlefbZMGcO7N5t9/3Tox19\ntLUI+/Wz+19/DWeeadv4kpLg448hKqr27tHjgU2b4MYbSzrQ1gp+S7OuJgOvqx60tZnGgXg8sHx5\n7YtAQQHcd1/pzEm1hctlZ2C6/nr48suyNS+NicpMjReAbQH/H/BSPUpZImnXC8br9VLk8xG9cWOd\ndHd0u61ozZplh1L4DVa/hZeTY3uazp1r5/8Mnk+7SxcrbHl5NsMJXGXCvwCFf6o0PwkJsG2bPSf4\nWDjk5VkRDdfvnDlWgB580E7yHe65VaWoCBYuhMMPt4WA2pweLjcX/vxnW71cmx2J8vJgzBgYNw46\nd669cIuK4PXXYelSuPtu+97V1phR/3OePt1aYF261N47VlxsV1659lpbcTRjhv1eGxV1PYK+vm7V\nOXNLdbJnzx65/fbb5YVnn5W9775bZ/OH7dwpcvXVIuvX2/3vvxdp317k9ttFli+3M8pUN1u3ivzt\nb3aGmsooLBRZu9ZuS5fa6duWLLFTr1XEtm32vlJTRVavtuGlpor8/nv13ENl7Nsn8txzIsnJIk89\nJbJrV+2FO3WqSMeOIpdfLrJhQ+2EK2Kf57XX2nT+5pvIptirCsXFIrNn2/e2UyeRO+6ILL2Li+22\nbVvl71Uw/vS+806R2FiR3r0rD9v/Tq9fX/Z37drw02zHDpGFC0U2bRJ59FGRCy8Uuf56+z0H3ldV\noAHM3BL5CXY9u3OA4UArxy0GcNX1zVTnVl+FT8TO/znuvvvE88gjIosXV/1NPQB27hQ591yRE04Q\nef99kYQEkZEj7YdVUxQWitx/f8UZxL59VnhvucW+3SASEyPSpo1IfLzIlClW0AIzjR07bOa1dKnI\n0KEiRx0lsmiRvd7u3SIvvywyalTkU8D5w3Bmlwv7nCVLRObNE0lJsYIQjtBXleJikWXLrMCffbZI\n9+42czyQ6xzIOQsXijz2mH1Gf/5zeBn5vn1ln+P69WUz8HDO//BDkZUrRYYMse/II49UXJbcsMGG\ns3q1yFdfWfHq3Flk+nTrFs79FxZavytW2P8XLRI55xz73APZtq303n7/3b7TxtgNSn+bN7fHVq6s\nONyVK+0326+fTae9e61bhw4i48fb8FavtoXYqmQpB5XwYatFnwT2YCemLgZOdo79Dxhf1zdTnVt9\nFr7CwkJ58MEHpXDrVpEHH6y9InIQGzaInHeeSKtWVlCqe27QYHbtssL0zDP7Z07bt9uP+O9/F4mO\nFmnb1s5X6s8Qt28XmTvXimBgphEdLXL00SKHHSbSpInIsceK/PZb2Wvv3GlFPZz782fEc+eKuN0i\nLVqIPP64jVtF5xcXW2snKUlk7Fjr96OPRM46K7y5UUOJwNq14Vve69fbAsyePSJPPmktgZtuqlx0\n9+wpDXPtWisG/oJFOJURu3fbtPniC/saf/+9LUytXRva/7Zt9torV9p0dbtLCzixsSJnnGEFpLI0\n27PHCs6559qCz+7dVlwGDiytxRCx9+BPz7lzRZo1K313XC6Rli1FevSw7058vMirr5bGfft2u/kp\nLrZp8+c/24Li7NmlArNkicihh9rC1/r1Nh2OOKL03po0sRbxvHn7W3zz59tCUlKSjWMoi/DHH63A\nnXLK/mm7fLl1P/FEkagoW/Cryny8B5vwTcCuXH4tdnoyX4Dw3QD8XNc3U51bfRa+PXv2yB133CE7\nN2wQGTy4/FyiFti1y35gtWV0bt0qcuutpRny7t02A2vf3mZIhx5qBaS8D3fDhrKZwpIlIhddZKv3\nli4tm1H52bPHVuEGZoiBBIsdlBYG5s4ViYuzGaZ/tYzA8P3xmTJFpHVrm5n7LdrCQpFnn7ViHkpE\ndu2y565evb8IGGP327e3majfEtq6tWw5accOm16tWtnqvm3bbFibNtlXK1SV59atNv6//WYLBP4w\nXa5SUWjZUuTuu61A7d1rwwl8Jvv2lVZBx8eLvPaadSsuFpkzR2TEiLLPYssWm3kfcURpGK1b27j7\nM/fFi61oBhZ8AjN//7u6fLm9fkKCtfj87+6uXVbwu3e39/b77yJ33VVqZbVoYZ/F6tWlz3DDBvsO\nbthg492kiUhiosi0adYSPP54G++1a0XeesuGmZZm4xb4zezbJ/LSSyInn2zDio0VueoqGw9/WFu2\nhH7/ROzzeuyxss/A/wv2HRw4MPTzLCy093naafZbquok9Aeb8G0F/uT8HxUkfL2B3Lq+merc6rPw\nFRcXy+LFi2XyP/8pe6+/3hbVKlju6GBi925b/ffbb6UZZ1ycbSNZsuTAqud27arcmlu/3lqDgRaU\nP7MLFju/xePP2DZtKi1xBwoT2HNdLnvu3Ln7V4tu2GDb3QKrsXbssPfes6e9RlTU/iIQKEzNmtlM\n7fPPRdq1E7ntNpupL1pkM+a4OJvxBabdnj3W8uzVy4rmli32mvPn28JFsLD6w/QLzbx59rotW9qC\nyoknWkti/nybPo89Zq3vY4+1aRN431u3Wvfbb7fxnDfPpo8/8/aLQahMfMeOUmELrBaMiRHp1s2m\ndaAwBhfYNm0S6dvXirHLtb+VVVm19fr19p1o3txa6+efX1ooiI+3hYHy2k+3bbNVnosX27AireLe\nt6/8NsD16yt+xwsLq6+Z4mATvkKgj4QWvv7A7rq+merc6rPwiVirb9y4cVK4fr1Inz62gcL/hdZR\n1WdtsHevyAMP2Mze7bYZ+Y8/1nwnkN27bacXf6b7zTc2M23Z0mZ0/sylIst3+/ayGdHKlWWFMhTF\nxSIzZ5Zai4sWWasmUDT8lkco/FV6J5xgLZZBg2ycjbHX6NXLFhhCWZRbttiM+9NPraXit0RGjLDi\nUllV6qZN9pVMSrJW1PXX22v4hXru3NAWtoiNU6tW1n/z5iI332xFMNzqdH8VrD/zX7TItl1On273\nK7Jqtm0Tufdee48VWVkV4bcwd+8uWyiorPq3JtvIa4uGIHzGxrNyjDGLgB9E5M/GmChgH9BNRH42\nxjwHnCgiPcK6WAOgW7du8tNPP9V1NMrF4/Hw+OOPc9dddxFbUAATJ8KTT9qR4tddB48/bvtmZ2XZ\nwVkulx0QV4VhFPWFoiI7xMDns7dTyTSn1cayZXDSSXboRUIC3HUXDBkCQYtpRITXWzocpDyysuyY\nyLVr7fCGrl1h0iRo08Y+0nDIybHDBpKT7bCFoiKbfklJFXej//lnO0/qiBHwl7/Y8FNSIhtSsnmz\nfU4xMfa5uVx2q6wLfUZGaTxTU6s+1CAnxz63cKb30+WwDhxjzGIR6VbX8aiISCapfhT4wBjTDHgf\nO6avqzFmMPAn7EK0Si3h8/nYs2cPy5Yto1u3brgeftgOas/JsaOuf/3Vehw6tDTn6d3bTpsSbm5Z\nT4mOhrS02g/3+ONh9WqbEbtcVnjCnHSnXMI5PzkZvv/ell98Pjsu0lmuMWwSE0vHU0YiWiefDEuW\nVE14Ahccadcu/PNSUw8svPIIHk9aESp6BzeRTFL9CXYIQx/gc8AALwOjgJEiMrMmIqiEJjY2lrvv\nvptp06bh8XisGrRrZ0fC9utn1yfq3RtOOcWO0J0zB1atgn/8o+6mBTkISEuzyZyWVnXRi4SkpNKw\nIxW9qtKunQqBcnBR4adrjDkdWCwi+wBE5D3gPWPMMUBr7HJEKyXc+lKlWomNjaW4uLisY3S0nQJj\nzJj9qzf/+187+3NGRmRFb0VRlIOIysqsCwCPs/7efP8mIitrPGZKWLjdbnJzc4kNrL/yW3/BpKba\nerMhQ+Ddd6FTp9qLqKIoSj2hsqrO84EnsIPW/wR8Amw3xvxhjHnFGDPaGKO5Zx0RExPDoEGDGDly\nJNnhLCMQG2utwZQUu7ZQenpNR1FRFKXeUaHwicgsEXlYRC4AEoEuwE3AD9hpy/4DLDfGZBtj/lvj\nsVXK4HK56NSpE3v37uWDDz7AG86E1SkptoNL27Z2Zt66mhZfURSljoikc4uIyDIR+beIjBKRjkAv\nbEeXVsCAmoqkUj5JSUlMnjyZp59+mhUrVoR3Ups28Nxztn/8zJl2qfOMjNALhOXkWMuwMS/epSjK\nQUXYwmeMaW6M6WWMud8YM8MYkwPMAo7AWn7X1VQklYrp2LEjt956K1dccQXLli0L76R27eCll2Dk\nSNvWd8opcNNNVgT9LFsGPXvaPu1z56r4KYpyUFBZr87hwJnOdgKwC1vNuQD4B7BQRHbXdCSVinG7\n3QwfPpyvvvqKyy67jJkzZ9I2nAW2unWz4/0++QS2b4epU+0y6a+8YkcOX365Fcgvv7SrsvoHsCmK\nojRgKpy5xRjjw3ZseQN4UUSW11bE6pr6PnNLKLKyshg/fjyJiYncd999xIQ7+KqoyP5u3Ah33GGH\nPcTFwS23wG232UFc110Hr75ae6tlKorSIDkYZm55CjgDuyLDKGdYw/fOtkBEGunC9fWT5ORkHnjg\nAcaOHUtmZiZp4U5v4l/mu0MHePttO0cW2LbA6Gjb9temjVZ1KopyUFBZr867RORcIB7oCUwHjgSe\nAzKNMWuNMW8ZY242kB7xzwAAIABJREFUxpxcU5E0xlxvjFltjPEYYxYbY3qHcU43Y8wUY8xKY4zP\nGDOlpuJXn4iLiyMmJoZhw4axZs2aA7mArd5s165UEKOj7YSN/ipQRVGUBkxYDTYi4hWRRSLynIhc\nISJtsZ1a7gYSgGeBhTURQWPMlcAkbHVrf2A58Jkx5vhKTj0LOBtYBGTWRNzqI3FxcTz11FM0bdqU\nESNGHJj4BeN2w2mn2UHvOvxBUZQGTkQ9FYwxTY0xZxtj7gReAP4FXOhcZ3MNxA9gHPC6iDwiInOx\nc4OuwYpuRTwvIh1E5Cogo4biVi9p06YNb731Fq1bt2b48OH8/PPPYZ9bUFBAVlaIGuykJDvd2UGw\nuoOiKI2bCoXPGJNqjLnUGPO0MeYHbK/Ob7ErNaQCU4FhwBEiklbdkTPGtAM6Au/53UTEh10don9F\n5zr+Gi1t27Zl0qRJGGPo27cvP/zwQ7l+s7KyyMvLIyMjg7/85S/06NEjtFjGxcH779u1dBRFURoo\nlXVu2YxdfmgntkPLeOx8nYtEpLCG4wbgnw7tjyD334FEY8whIrK9FuLRIGnbti2ff/45M2fOZOTI\nkXz00Uccf3xpDXFeXh4rVqzgmmuuITU1lcLCQrKysjjmmGMYMGAAn376Kd26OZ2z3G444QS74kPv\n3tW/ZoyiKEotUVlV5xjgOBFJEpGLReRxEfm2lkQP7IwwALlB7juDjlcLxpgbjDE/GWN+2r794NDT\nxMREBg4cyKBBg7jqqqvIzLTNnTk5OQwaNIhevXrRtm1bdu3aRXFxMTNmzODtt99m9OjRXHHFFaxa\ntQqwIklKCjzyCGzYoD08FUVpsFRo8YnIq9UdoDGmJXBYZf5EJNjKq3FEZDIwGew4vtoOv6aIjY3l\n//7v/1i9ejUfffQRgwcP5sMPP8Tj8fDtt9/SqVMnipzemonOap133nknXq+XO+64g2effZa//e1v\nTJkyhfiePWHQIDvWr4EvaKsoSuOkFpfSLOEy7BRnlWEotexaUtbq81t6O1HCIjk5mb///e/07NmT\nSZMmkZGRwaxZs+jatWtI//Hx8dxyyy1ccsklTJo0idzcXLKysohPTraW36pVdklrnclFUZQGRq3n\nWiLysoiYyjbHu9/qC176qBOQo+17kdG5c2dmz55N8+bNKxQ9P23atGHKlCm89957XHDBBQwbNozs\noiJ48UWYNk1XclcUpUFSFxZf2IjIOmPMKqyVOBPAGONy9j+vy7g1VLp06cJnn31WUqUZjv8FCxYQ\nFxfH5s2b8fl8dkD7kiXwxx92tpfypjHLz7ezwMTGWitRURSlHtAQ6qnGAdc6q0KcB7wKHI1dIBcA\nY0wPY4zXGNMjwO0QZyjGpdiq0SMD9hs14Yqen9TUVGJjYznnnHO4/fbbyQMYOtTO5jJkiJ3oet06\nu3k8dpD7r7/CiBFwzDF28PuCBaVToSmKotQh9driAxCRd4wxccBdwAPYmVsuEpHA9XcMEOX8+jkO\nO97PTzvstGsE+VPCwO12c8455zBhwgR+XLyY3mPH4jrrLLjySujaFUSgeXMYPhx+/x1+/NFag3Pm\nwPTpViTbtIH589X6UxSlTqlwdYbGTENcnaE2WLNmDTfddBPvvfceCQkJkJ1tqzR9PsjMhCuugJYt\n7bye7drZnp8ej+0MM3GiXero5JPDGweYlWVXhtAVIRSlwXAwrM6gKGVISUkhNTW1ZPgDSUmlwxra\ntYOFC+1g98ChDjEx0KUL3H03nH667Q368ceQkGCtwKys/YXwp5/gqqvsIrlvvKHipyhKtdEQ2viU\nekRMTAwDBgzgscceo6CgYH8PKSnlj+/r3NkK43nnQb9+cNJJ8NBDcOaZ8N131jLMyICvv4b+/aF7\nd7joIiuciqIo1YRafEpEuN1uevTowXPPPUdeXh6xsbGRXaBTJ3jqKWjRAi68EEaOtO2EF14Igwdb\nS1DEWodXXQVjx8JRR1mx1DGDiqJUA9rGVw7axlc+RUVFTJo0id27dzN69GhSDqSzSkGBHeawcaO1\nEhcutL1AR460gtehg60yXbfOuk2bZqtFFUWp1zSENj4VvnJQ4auY9PR0zjjjDFJTU3nllVcqHQwf\nFhkZtprUvwAu2I4zN95oO8w89phtF1QUpd7SEIRP646UAyItLY05c+bQpEkT+vXrx7ffflv1i6am\nlhU9sEshPfEErFwJU6boCvDK/7d35vFRVef/fz8hhhhCEmM2AsQY0Soi0qog1AXcQBSQRS1SFK2o\nVEF+9atYC1apigJWtFq3VqO4l+IOolKgyBIgIKbshIRNluwL2Ujy/P44M2EyTJIJSUgmOe/X674m\n99xzz3IvzGfOOc95HoulwVjhs5ww3bt3Z8GCBTz//POMHDmSlStXNk1FERHGGnTbNusmzWKxNBgr\nfJYGER4ezujRo3nppZcYPXo0O3fubPxKAgPh97+HTZtsIFyLxdJgrPBZGoy/vz/Dhg3jtttu469/\n/StbtzZBRKnYWPjHP+DVV43BS23k50N6+jE3aunpxpjGYrFYsMJnaSSCgoKYMGECCxYs4PLLL+eH\nH35o/Eri4uCaa+D222H9+urC5vz7p59MvMCEBDjrLHP07AkPPADZ2d7VU1YG+/Y1fvstFkuLwAqf\npdGIi4tj5cqVPPzww4waNYoffvjhmIcXD5SVlbHPITDp6ens2rWr6twjgYEwebLZ53fxxceEzVXk\n+vQxrtPWrIHUVHP88IPxDvPcc+aaqdy4WXOfNs3NhSeeMOVY8bNYWiV2A7ulUYmNjWXSpEkAjBgx\ngvHjxzNlyhRC3FyObd26lblz5/L2228zc+ZM7rzzTioqKoiKimL+/Pn069fPcwUxMbBokRGoykqT\n5udX/e/g4OreY4qKoFMneOcdEyVi1izjHebCC40QXn+9cYm2axc8/zwsXAhTpx5vYWqxWFoHqmoP\nD8dFF12klhOntLRUP/jgA42OjtbJkyfroUOHqq4tW7ZMTznlFI2OjtYHH3xQTz/9dE1MTNQtW7bo\nzJkzNTo6WteuXauqqnl5eXr06NGGN+jIEdVNm1QvuUTVz0+1Y0fVdu1UO3RQPecc1ZEjVQMCVM86\nSzU5WfXQIdVLL1Xdtq3hdVssbQhgnbaA7/DaDjviszQJAQEB3HrrrZx99tncfPPNbN68mVmzZpGf\nn8+YMWP4/vvv6datGxEREUyePJm4uDj8/PyIj4+nffv23H777XzwwQc8/fTTXHXVVfzud78joCEj\nsKAg4yv022/NWl9goJnuLCqCxx83a4ZLlhiPMVFRZkTp7w+jRsGCBdZrjMXSirCeW2rAem5pPP73\nv/8xfPhwdu3aRceOHZkwYQJPPvlkjUKWm5vLhAkTqKioIC4ujo8++og33niDQYMG4dcU/joLC83h\n7nptzx5jFNO9OzzyiIkqYbFYasUXPLfYEZ+lyenRowcrVqxg8+bNxMXF0aVLl1pHb2FhYcyYMYNh\nw4ZRWlrKvHnzePbZZ+nevTvx8fGN38DgYHO4ExdnYggOGmSMY15+2Ywca6OoyIwWy8qMUJaXW8G0\nWFoYdsRXA3bE1/hUVlbWa8SWmZlJQEAA5eXlDBw4EIAvv/zyxJxiN4SffjKOsxMTTRBdJwcPGmOa\nqCgjcNu3w8yZJsJEebkxnikvhy+/NHm84eefjT/S+ka9sFhaCL4w4rPbGSwnjfpOU0ZERBASEkJ4\neDgff/wxoaGhvP3227VukWgSevQwWxyGDDFbI3btgtWrzZaKyy4zlqKzZ5vz776Du+6Cb74xG+nb\nt4d5845tus/NNZ/5+dXrKCkx5fTpA//3f3bDvcXShNipTotPkJCQwBtvvMHtt9/O6NGjm2bKsyb8\n/Ey8wDVroH9/qKgw8QQHDjQCdeWVJnrEN9/AOeeYEVtgoDGWOXgQfv1rE3D3n/8006WPPQYvvmjS\nEhLMKO/vf4e5c01opl/+0hjWWCyWJsFOddaAnepseZSUlDB9+nRSUlJ4+umn6d69O/4nUyDKyoxI\nVVYem+KsrITMTHMeF+f5vvR0+OgjE1YpOhr27oXOneHAATj/fDOVGhlp/JDGxcHIkcaYZuBAz2uP\nFksLxhemOq3w1YAVvpbJvn37GDBgAJmZmTz66KOMHTuW2NjY5m5W3ZSXG08wISFmujMsDHbuNBHm\nX3/d+CJ19mP9eiN6gwebzfberg9aLC0AK3w+jBW+lktmZiabN29myJAhREVF8f7779OrV6+G7fNr\nLjIzq3uZcbJmDfzmN2ba829/OyaKtZVTWFjdg014uBFabygqMuuOJ9twyNLq8AXhs8YtFp8jIiKC\nK664glWrVtG9e3cGDhzI9OnTT77RS2PgSfQAevc21qH/+x/87ndmutRJZmZ1x9zr1kHfvtV9lvbo\nASNGmGlU1+fiKZ7hvn1w//1wxRXHfJlaLK0YK3wWn6V79+68//77LFq0iM8++4z169dz+PDhepdT\nWFhIeUuM8dezJ3z+uRG6m282U6Br1hwvcv37wxlnwI8/HnPMvXQp7N5txOzPf4atW83xzDOwebPx\nXpOba8ocOhT+8x/jANwa1VjaAHaqswbsVKfvUFZWxhNPPMHzzz9P165d+eCDD+jdu3eN+TMzMyks\nLMTf35/CwkKeeeYZ+vbty7Bhw1rmeuGuXTB6NKxda7ZH9O0Lc+YcM3ypaVozM9OI3aBBcOQInHKK\nEbaKCiOcgYFm7+GFF8Ibb8CWLfDaa2ZqtVs366TbckL4wlSnFb4asMLnW5SVlbF9+3ZmzZrF119/\nzbx587j44osJdrGKLC8v58cff2T06NGkp6fj7+9P+/bt6dixIzk5OXTq1Il///vf9OzZEzCu08LC\nwpqrS9XJzT0WkSIiwvu1OzBTmWVlRiADAowXmsceM8L42mtGBMPCTPrAgWa6c/x4MwL0xuvM4cNm\nfdEZJSMwsO41Sff2RUVZoW0l+ILwNbuX7JZ62OgMvklBQYEmJiZqaGioDhs2TDdt2qSqqhkZGTpj\nxgwNCQnRq6++WteuXaszZ87U6dOn6/79+3XTpk06YsQITUhI0E2bNmlWVpZeffXVumPHjmbuUROR\nl6ealXV8+v79qpMnq3bqpDp8uOrevdWvp6aaY+9e85mUpNqliyqoipjIF506qa5YoZqTU/3e0tLq\n50ePqi5fbvLPnn38dYtPgg9EZ2j2BnjVSBgP7ABKgGTgai/uuRf4DjgE5AErgOu8rdMKn+9SUVGh\nSUlJGhcXpxEREfr5559rnz59NCIiQpctW6Z5eXmqakInlbp82WZkZOjDDz+svXv31sTERP3lL3+p\nPXr00OTk5ObqSvNQXKy6YYPq2WerXn65CdOUmqq6eLERNxHVwEDz9REcrDpsmOrGjappaSb008SJ\nJr1vX1NOaqrqli2qs2aZT1UT7mnGDNXwcNVHHlFNTDRCaPF5rPA1juiNBiqAacAA4F2gGOhRx317\ngDeAm4BrgXeASmCoN/Va4fN99u/frzNmzNDg4GDt1auXbtiwoc57Dhw4oH369NHIyEhdtmyZXnXV\nVRoZGVkVH7BNsW2bau/e5msCjEgtXmzS5841n2lpqgUF1e8rLjZiecEFRiTBjAQ7dFANDVV9800T\nC/H001WXLTOjzEsuUV27VvXAAdWKivq18+hRU0ZaWv1HjfWty1InviB8LX6NT0S2AStU9S7HuR+w\nEdioqr+t5b4IVc10S1sJlKrqgLrqtWt8rYPy8nL27dtX5fPTG3Jzc8nPzycuLo7c3FwWL17MtGnT\n+OKLL+jWrVsTt7iFkZtrLEDBrOE5XcWVl9dtAZqdbfYGOvcWBgYaY5vf/MZ4sunWzXiqKS83BjV/\n+pNZ65s502zFqK38zMxjZX/xBUyfbtInTICHHqp5m4iT8nKzJSQ72/hYbYpwV20UX1jja9HCJyIJ\nQCpwvap+45L+OPCgqp5ez/JeAa5R1V/UldcKn8VJfn4+99xzDwUFBbz//vstx+DFV0lPPyagTpzR\nLZ59FhYtMk6/hw0z4ldSYgTYaTyTnW3EMzUV2rUz1q233262Zdx2G/TqBS+9ZIQWzD3BwcZQx9/f\neMz55BP4y1/MdpBvv62fMY6lVnxB+Fr6pp1zHZ9b3dK3AOEiEqmqGfUory+wvVFaZmkzhISE8Oyz\nzzJq1CgWL17MhRdeiL+/P126dDm5vkJbC54cjPv7m4C/r71mNuQPHWpGhZGRJhLGtm0gYiZdO3SA\nSy81US/Cwo75TQ0MhO+/hzvuMKO44mKTv1076NrVWKmee66JstGxI3z6KaxYAf/4B9x9txkl1tey\n9OBB4/UmJKTuUaYrubnmHjvSbB6ae661tgMYAygQ5pZ+jSP9nHqUdZfjngG15LkHWAesi4uL8zR9\nbWnDJCcna2BgoAIaFhamM2bM0LS0tOZuVuskKUk1IUH1zDNVr7jCrBmmpRlDmbQ0Y5VaE/v3q06d\nqvr11yb/xo2qN92keuqpZo1x8WLV3bvN+t4335i1y3PPVX38cc+Wrq4UFBxrx4oVqlFRqqeconre\neabN3hjobNigeu21qmvWtMo1Ruwa3/GISCjQqa58qrpVRMYA7wGnqWquSxnXYCw2f6GqdY7gROQi\n4L/Am6o62Zt22qlOiyf27NlTtW44ePBggoODmTdvHj169PBqCrS8vJz8/HzCw8OrygoPD7fTp55w\neuEJCDAju/pQUmLuc46oCgvNKKuszOxbdFJZaaZYH3sMli838RWfe86El8rPN+U49yjm58O0afDV\nV+a+Dh3gzjth7FgTeWPpUpgyBW655Vi9zr2TMTFmijc93Uzhnn22cRN3xx2tzluOL0x1Nsco7m7M\nyKvWw5F3sOP8DLcybnakR3pRXwJwEPgCaOdtO61Vp6UuduzYoVOmTNHg4GDt27evbty4sdb8hw4d\n0ldeeUUvvfRS/fTTTzUwMFDbt2+v/fr1q3bvkSNHmrrpFncKCsyoMj7e7Ev8+mvV665TjY3Vqj2K\n/v5mFJqUdGw/Y3HxsfuXLDGjSqclK5jRYKdOqs89Z9KdI84dO1R//WtT5/799Wun68g3NfV4q9ra\n2L+/7lFtA8EHRnzN3oBaG2dES4GBbunTgCwv7o/C7P9LAoLqU7cVPos3lJaWanJysl5wwQUaGRmp\nS5Ys0QIPX0QpKSnas2dPDQ4O1gsuuKBqqjQpKUl79+6tERERmpSUpEeOHNE//OEPumnTJj1q97Wd\nfPbuVZ0yRbV9e7OP8e67VVNSjonMoUO1379797G8zv2LkyapRkcbYUxNNfmOHFEdN87U06WLmTZ1\n34qRkXGsnLQ0M2U7dKjZGuIU41NPVR0yxLQxJ8cIW3Gxucf1309BgXEWEBOjeumlTSp+VvgaR/y2\nAf9wOfcDfgLeq+O+YMx63Q5vRobuhxU+S33IyMjQxMREDQ4O1iFDhmhKSorm5eVpaWmprlixQmNj\nY/W6667TlJQUzcnJ0bS0tCphy8jI0BdeeEG7deumixYt0iFDhuhpp52mM2bM0L3unlMsTU9pqRGO\njAwjUA2luNgIojtHjhhhnDBB9bTTVB991JynpZlRZbduWjVy9DTiTEtTXbVKtWtX1aAg1R49VDt3\nVh071owsZ8wwey2dghkcbOp6+22TXts6aQOwwtc4wufcwD4Vs4E9EbcN7MCVQDlwpUvat0AZcBtw\nqevhTb1W+Cz1paKiQletWqVdu3bVDh06aP/+/fWhhx7SsLAwnThxoh6qZbRQUFCgEydO1ODgYB03\nbpwuXLhQO3bsqGeccYamOkcJltZJcbEZjXXooNVGckOHGtFyndb09G/o0CEzZXrppar33msE8+OP\njdA5p1udxjdZWar33GOE8qqrjKFNI7uK8wXha9H7+JyIyHhgCtAV2AQ8rKqLXa73B5ZgLDaXOtJq\n7JiqSl11WuMWy4ly+PBh9uzZw5gxY8jLy6tymB3o3FdWAyUlJezbt4/i4mLOP/98tm/fzpw5c/Dz\n8+Pxxx8nxgaJbd24OhOvrDRbNFycrNdJdjYEBRkjnpiYY+VB9e0WRUUmNNWddxpjm/vvh9//3tSV\nm1t/J+Nu+IJxi08IX3Nghc/SUDIzMykpKaFLly71uq+yshI/h1Vgeno6gwYNIj4+npkzZxIcHExY\nWBghISF2D6GlYWRnm0DHw4aZcFehoWZzf+fOZu/kCYqfLwif3T1psTQRERER9RY9oEr0AOLj45k/\nfz6pqan06tWL8847j/79+/P666+TmZlZSynHc/jwYSorKzl8+DDp6ens2rWLoqKierfP0koIDzeB\niteuNdsqOnc2fzdA9HwFK3wWSwune/furFq1il27drFq1So6dOjA448/zrBhw1i/fj0HDx6s9f6y\nsjJWr17NNddcw9///ncuuugiEhISuOCCC7j33nvZs2cPYEaa2U6/nJa2Q7du8OSTMH8+/OpXrV70\nwAqfxeITREREEB8fz69+9SsWLlzIkiVLyM/Pp3fv3vTp04eVK1d6vC87O5tp06Zx7bXXcsYZZ/DY\nY49x0UUX8dNPP7F48WJWr17N4MGD2b59O6tWreKGG25g/fr1/Pzzzye5h5ZmJTCw/k4CfBi7SGCx\n+BhhYWGEhYWxbNkyDh48yGuvvcaNN97IvHnziI+PJygoiJiYGHbu3MkjjzzCqlWr+Prrr7n44os5\nfPgwERERVZHpFy5cyKRJk7jrrrvo378/FRUV9OnTh+joaL766it69erVzL21WBofa9xSA9a4xeIr\nlJSUsHLlSgYOHIiqEhsby0svvcSkSZMIDQ1l7ty5tQpYeno6I0aMIC8vjy+//JL9+/fz3//+l3nz\n5vHxxx/Ts2fPk9gbi6/jC8YtVvhqwAqfxddIT0+nsLCQ5557ji+//JKhQ4fy1FNPERcXV+e92dnZ\nlJWVERMTQ2VlJbm5uYwfP54ff/yRuXPnEhMTg5+fHwEBAcTWcw2opKSEkpISgoKC2Ldv3wmXY/EN\nrPD5MFb4LL5KUVERhw8fJioqiqCgoBMuJzMzk+nTp/O3v/0NgFNOOYXo6Gg+/PBDEhISiIqKqnNL\nxZ49e3j55ZdJSkri4osv5oUXXsDf35/IyEg+/vhj+vXrh5+fH4cPH6a8vNyKYSvACp8PY4XPYjGj\nNaehS1lZGS+88AJvvfUWERERPPTQQ4wYMYIE12gHLqxbt45bbrmFvLw8oqOjKSgo4MMPPyQiIoJX\nXnmF9957jzlz5jBw4ED69evH0aNH+fDDDznnnHOIioo6md20NCJW+HwYK3wWy/GUlJSQnp7Ou+++\ny5w5cwgODuaTTz4hISGBiIgIgoKCKCkpYc2aNYwcOZIbbriBqVOnEh4eTklJSdWIrqSkhNWrV3Pb\nbbeRmJhIUlISBQUFvPjii3Tt2pX58+c3+tpiUVFRg0bAFu/wBeFrdp9pLfWwvjotlpopLS3VtLQ0\nTUxM1Hbt2mlISIiOGzdO165dqxMnTtTw8HCdMWOG5tXhCHnJkiUaGhqqzzzzjBYUFGhKSoredddd\nmpCQoElJSZqWlqapqal1luOJo0ePalpamubk5OiWLVt04sSJmpKSovtdwgAdPXpUSxvZV2VbBx/w\n1dnsDWiphxU+i6VuKioqdNu2bfriiy9q586d1c/PTzt16qQrVqzwOqxSampqNfHJyMjQsWPHakBA\ngIqIBgYG6oABA3Tjxo21Ovp2JS8vT2fMmKEdO3bU7t27a4cOHTQyMlL9/Pw0Nja2qn1ffPGFPvXU\nU7p3717Nyck5oWdgqY4vCJ+d6qwBO9VpsXhPeXk52dnZFBYWEhgY2GAjlfz8fBYsWMDFF19MdnY2\nY8aMYe/evXTt2pX333+fiIgIYmJiPE5d7tmzh6lTp7Jo0SJef/11Zs+eza233srIkSPJz8/nnXfe\n4c0332T+/Pl89913vPzyy3Ts2JH4+HjeeustunXr1qC2u1NSUkJ2dnabMdyxU50+fNgRn8XSvLiO\nGDMyMjQlJUWHDh2qfn5+GhQUpGPGjNFNmzZpVlZWVdT6DRs26Hnnnafx8fGalJSkqqpZWVnVyiou\nLtaPPvpIu3TpooMHD9a1a9fq+PHj9cILL9QePXroxo0b9ejRo5qamqoHDhyod7tLS0s1NTW16pg8\nebLGxcXp8uXLNcslAGxWE0dCby7wgRFfszegpR5W+CyWlkdBQYGmpaXpihUrNDo6Wk899VTt2bOn\n3n333bpo0SKNiorS4cOH644dO+os57777tNp06ZpcXGxHjlyRNPS0vSaa67R2NhYffTRRzUgIEDj\n4uJ0xYoV1dYFayMrK0unTJmigPr5+WloaKjGxMTogw8+qIGBgXrhhRfqjh07NCsrSy+77DJNTk7W\n1NTUJhPB5hBXK3w+fFjhs1haNgcOHNANGzZo3759NTIyUkNDQ/XRRx/1+sv+yJEjWlxcXC0tIyND\n//jHP2pUVJQuXLhQJ06cqP7+/hobG6vLly/X1NTUGtcZs7KydPjw4dq1a1ddvny5btmyRWfOnKlp\naWlaWlqqycnJevnll2vv3r11yZIlesMNN6ifn58GBARor169NCUlpcHPJCcnR9PS0jQjI0OTk5P1\nsssu07Vr1+pulwjwnvrdmFjh8+HDCp/F4hvk5OTogQMHqgSmoZSWllYJRXFxsW7ZsqVqFOfv769n\nnXWWrlq1Svfv318lgqmpqTp16lQ999xzdcOGDdXKcmX37t06YMAA7dixo7766qu6Y8cO3bBhg157\n7bXauXNnXb58eZUl6+7du3Xv3r1et3v37t16ySWXaGBgoHbp0kWDgoL0/PPPV0AjIiJ02bJleuTI\nEX3ooYf0kUce0S1btmhqamqDn5c7Vvh8+LDCZ7FYnDjX7VJSUnTs2LHq7++vISEh+otf/EL/9a9/\naUhIiEZHR2tycnKdZeXl5Wlqamq1dcdDhw7pAw88oCKiIqKABgQEaHR0tC5btqxqFFcT27Zt00GD\nBukll1yiS5YGop6rAAAPcklEQVQs0Ztuukk3btyoOTk5umPHDn333Xc1IiJCFy1apLNnz9awsDAV\nEQ0NDdXvvvuuUUeAviB81qqzBqxVp8Vi8URRURHp6enMnTuX1NRUvv32Wx577DFuueUW4uPjT7hc\np5ccPz8/ysvL2bVrF4sXL2bWrFm0b9+eM888k8TERHr16kVAQEDVfatXr+aWW24hJCSE+fPnc845\n55Cfn09ISEhVnvLycubOncv9999Pjx49eOuttwgODmbnzp2MHDmS22+/nQkTJhAYGNhgq1xfsOq0\nwlcDVvgsFkttlJSUUFlZycGDB4mLi6vTb2l9qayspLy8nH379lFYWMiDDz7IunXrmDRpEmPHjiUw\nMJBdu3YxatQoxo4dy8MPP0yXLl1qLS89PZ2wsDDCw8Or0leuXMnw4cM5fPgwfn5+dO7cmdWrV5+w\n+Fnh82Gs8FkslpZEfn4+P/30EzfeeCN5eXmICB07dmTOnDnceuutDXLHdvDgQYqKigDaxIjPBqK1\nWCwWHyAkJITLLruMzZs3U1JSgp+fH5WVlcTHx+Pn59egsmNiYhqplb6BFT6LxWLxIdqKB5impGE/\nEywWi8Vi8TGs8FksFoulTWGFz2KxWCxtCit8FovFYmlTWOGzWCwWS5vCCp/FYrFY2hRW+CwWi8XS\nprCeW2pARDKA3Sd4ewSQ2YjNaenY/rZubH9bP43Z5zNUNbKRymoSrPA1ASKyrqW77GlMbH9bN7a/\nrZ+21mc71WmxWCyWNoUVPovFYrG0KazwNQ1vNHcDTjK2v60b29/WT5vqs13js1gsFkubwo74LBaL\nxdKmsMJnsVgsljaFFb5GQkS6i8hiESkSkZ9FZLqItGvudtWFiHQTkddF5CcRqRCRpR7yiIg8JiJ7\nRaRYRP4rIr085KvzGXhbVlMgIjeLyBcisl9ECkUkWURGe8g3XkR2iEiJI8/VHvJ0FpFPRaRARDJF\n5GUROS4EtjdlNRUiMkpEVopIlqP+bSIyVUQCXPK0infrCcc7KhQRFZHg+rbTF/osIuMc/XM/7qtv\nG32hv42GqtqjgQdwGvAz8D1wLXAfcAR4qrnb5kXbhwF7gX8BW4ClHvL8ESgGHgCuARZgNrvG1PcZ\neFNWE/Z1FfABcAtwFTAbUGCiS57RQAUwDRgAvOtobw+XPKcA/wPWAzcAY4BDwHtu9dVZVhP3917g\nKWC4o/4pjvpfbm3vtob+fwAcdLzj4NbYZ2Cco38DgEtdjqjW2N9Ge27N3YDWcDj+MeQAIS5pjwBF\nrmkt8QD8XP6eh5vwAYFAHvC4S1oHIMP1P4U3z8DbspqwrxEe0j4A0lzOtwFvuT4fIAUXUeOYoJ3p\nknYLUAmcXZ+ymuF9Pw3kAtKa3q2Hfl4BZAP/h4vwtbY+c0z4gmu43qr621iHnepsHK4HFqlqvkva\nR8CpwJXN0yTvUNXKOrL0A0KAT1zuOQJ8iem3E2+egbdlNQmq6skl0wYgFkBEEoBz3NpXiRkNu/d1\nraqmuaR9BpQBg+pZ1skmC3BOdbaad+uKY3rub8B0jnfD1Sr7XAttrb9eYYWvcTgX2OqaoKp7ML+W\nzm2WFjUe52JGNzvc0rdQvW/ePANvyzqZ9AW2O/52tmGrW54tQLiIRLrkc+9rGZBK9b56U1aTIyLt\nRCRIRC4DJgGvqvm53lrf7X1Ae+AVD9daa59TRaTcsY57r0t6a+1vg/Bv7ga0Ek7DTB+5k+O45suc\nBhSqaoVbeg4QJCIBji99b56Bt2WdFByGJjcBd7m0D47vR47L9Qy876s3ZZ0MjmCEAMw648MubWhV\n71ZETgf+AvxWVY+KiHuW1tbnA5g15DVAO+A3wGsiEqSqL9Sjjb7S30bBCp+lTSIi8Zj1vc9VNbFZ\nG9P09AOCgN7A48DLwO+btUVNx9PAalVd0NwNORmo6iJgkUvSQhEJBKaKyIvN1KwWjxW+xiEHCPWQ\nfhrHfuH7KjlAsIi0c/uldxpQ5PILz5tn4G1ZTYqIhAMLMWGnxrhccrYzlOq/fk9zu15bXzfWs6wm\nR1XXO/78QUQygXdE5Hla2bsVkfMxo/crRCTMkezcYhIqIhX1aKdP9LkG5mGMreJpG/2tN3aNr3HY\nitsct4h0xfync1/j8TW2YqZQurmlu68JePMMvC2ryRCz1+4rjIHHjapa5HLZ2Qb39YpzgWxVzXDJ\n597XACCB6n31pqyTjVMEz6SVvVvgbMxWk1WYL+kcjq3z7cMYvLS2PntCXT7bQn/rjRW+xmEhMFBE\nOrqk3YrZ77KseZrUaKwE8oGbnQkO8RiC6bcTb56Bt2U1CSLij7GqPBsYpKqHXa+r6i6MoYtr+/wc\n5+59vUREznBJG4pZR/umnmWdbH7t+EyjFb1bBz9g9rO5Hs85rg0GZtWjnb7SZ0+Mwliz7qZt9Lf+\nNPd+itZwYIb6B4DvMJs67wEK8YG9LZhfdKMcxypgk8t5kCPPHzHWXfcDVwNfY/5jRdf3GXhTVhP2\n9Q3Mr+BJVN/seynQ3pHHuUdvKuaLM5GaN7AnY75QR2M2Ste0gb3Gspq4v99g9rFdD1wHPOl4Jx/V\n5334wrut5RmMw/MG9lbRZ+DfGMcE1wM3AnM53ilDq+lvoz235m5AazmA7sB/HF9sBzCWZe2au11e\ntDve8R/F0xHvyCPAnzDTRcXAcuCXJ/IMvC2rifqaXldfHfnGAzuBUszU4NUeyuqC2btXiNkb9wqO\nHwpu+eosqwn7+xeMQBdi1hnXAxOBU+r7Plr6u63lGYzjeOFrNX0GnsE4Sihy1J8MjD2RNvpCfxvr\nsGGJLBaLxdKmsGt8FovFYmlTWOGzWCwWS5vCCp/FYrFY2hRW+CwWi8XSprDCZ7FYLJY2hRU+i8Vi\nsbQprPBZmhUReUJEVEQWebg2T0SWnsS29He0pcfJqrM+iMh5IrJcRI442hlfQz4VkQdczu8RkZtO\nVjtd6o1yvN94t/QW/ZwtrR8rfJaWwnUicklzN6KFMwsIw7hH64vZZOyJvhjXbE7uwYRfOtlEAX/G\nOElwZT2mjaknu0EWC9joDJaWQTawH+MRojm+oE8KIhKoqiUNKOJc4AtVXVxbJlVd3YA6asUR3byd\nNsATv5oo303WRoulLuyIz9ISUEwctaEickFNmRzTZpke0t2n9tJFZLaIPCoiB0QkT0SeF8NgEdkk\nIgUi8pmIeAoUHCsiXzmmFPeIyH0e6rxcRJaJSJGIZInIm64OfkVknKNdvUVkqYgUcywArKe+9RKR\nxY7yckTkfRGJdlyLFxEFzgL+n6PcpbWUVfU8HPkuAu5wpKuIjHPJe7fjeZSKyG4RecStrEQRWSci\nN4nIJqAE6CMinUTkLRHZJSLFIrJdRJ5yRKlwxjtMcRSzxFm349pxU51iIsS/JCIHRaRERNaKyHVu\nbVnqmP6+TUR2iki+iCwUkS5u+f7ouF4iIodE5BsRianpeVnaHlb4LC2FfwE7MKO+xuA3mMCrdwIz\ngT8Af8X4H5wG3AdcCczwcO8/gZ+AEcAC4FURudF5UUR+DXyPcUw9CpiMcVb9toeyPgS+dFz/ylND\nRSQSWIpxGH4bxp/mlcB3DiE5gJkaPIgJntsX7wPJ/h4TMmaB476+GMfCiMjDwKsYn6M3Ov7+i+uP\nCAfxmGc4A+MMOQ2IwIzU/wAMwkzD3okJ/YOjzc5Yh/e71F0TbzrufxoYDuwFvhaRy9zy9QEeAB7C\nTOH+CuN8HEefbgcew7zrgcAEjK/UDrXUbWlrNLezUHu07QN4Ash0/D0OE83gHMf5PGCpp7xuZSjw\ngMt5OubLrp1L2hqgHDjTJW0mcMjlvL+jrDfcyv8OE9Xbeb4cWOKW5yrHvT1c+qLAg148g2cxTqRD\nXNL6OO4f7dav2V6U5/481gGJbnlCMM6r/+yWPh0jsO0c54mO8nrVUac/RrRLgABHWg/Hvf3d8jqf\ns/NZnQdUAne45PHDONhe5JK2FMgDTnNJm+wo61TH+cvAv5v737U9WvZhR3yWlsR7wB5M6JOGslSr\nR4neCaSrappbWqRzes6FT93O5wMXiUg7MfHH+gKfiIi/88DEgjuKmVZ05Wsv2tob+FbN2hcAqpqE\nETr3EU9j0RczCvqXWz/+A0Rjok842a+qP7re7Jg2niwimx3TuEeB9zExCePq2ZZLMF7/qwxyVLXS\nce7e/7Wq6hq9frPjs7Pj80dgsIg86ZhmblfPtljaAFb4LC0GVS3HjMJ+K9WDvJ4IuW7nZTWkCSYa\nuyuHPZz7Y6b3TsNEof475sveeZRi4vR1dbv3kBdt7VRDvkNAuBf3nwgRjs9NVO/HEke6az88tW0y\nMBvzI2EYRrzvd1wLrGdbOgGFqlrkln4ICBKR9i5pnt6ha51vYaY6bwGSgEOOtUcrgJYqrFWnpaXx\nFiZw6xQP10pwE6kajFMaSpSH83JMwM1AzNTaE5h1M3d+djv3Ju7XAQ91ghl5JXtx/4mQ7fi8Ec/C\nts3lb099uBmYp6pVa7Ii0v0E23IACBaRIDfxiwaKVLXU24IcI8UXgBdEpCtmnfFpTPy4106wfZZW\nhhU+S4tCVUtFZDbGkCIZMwpxsg/oKCKdVXW/I+069zIageHAQrfzZMfU6RERWQ38QlWnN1J9ScAE\nEemoqgUAYvY0xmOmUBtKGcePwlZhAonGqqo307HunIoZ5boyxu3cfTRWE2sx4joKeBfMVKrj/IT7\nr6p7gWdF5E5MkFWLBbDCZ2mZvI6ZruoHLHNJ/wbzZf2WiDwPnImxzmxsrheRpx11jwCuxUznOXkE\nWCwilRgDnALMutYNwJ9UdXs96/srxvpwkYg8BwRjDF5SgH83pCMOtgIDRWQgJlp8mqpmicgTwIuO\naeX/YpY+zgEGqOrwOsr8DpgkIkmYjehjgG5uefZg3tcdIpIHHFXVde4FqeoWEfkQeNmxJSQVE7n+\nXMxz8RoReR0zml2NMYQZAJyN5xkESxvFrvFZWhyO6a4XPKRnAiMxhhefAb/FWBI2NndjzOSdZv73\nq+oXLu34AbgCiATmYrYrPIIxwfdmTa8aqpqB+YIuwWx/eAVjOXqtNmCjuAtPAVuATzCjqyGOemdi\ntgRcD3zuqHuMo+66mO7I/5TjswyY5JpBzWb98RiDn2WOumtiPPAO8LijLWcANzqedX1YhXk3b2Om\noocD41X1s3qWY2nFiKo3SxAWi8VisbQO7IjPYrFYLG0KK3wWi8ViaVNY4bNYLBZLm8IKn8VisVja\nFFb4LBaLxdKmsMJnsVgsljaFFT6LxWKxtCms8FksFoulTfH/ATb7QhNg+tTHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQjtgeDAkkiG",
        "colab_type": "text"
      },
      "source": [
        "We have seen how a non-linear activation function has resulted in a convergence of our weight values as our number of iterations increased. This is an example of a simple three-neuron +bias feed forward network; there were no hidden layers and there was only one output. In the following exercise we will use a generalized delta rule with batch backpropagation of errors on the full dataset. We will use the same activation function but include a hidden layer in the neural network. In general we can work with any number of hidden layers although in general one suffices. It has been shown that one hidden layer is sufficient to approximate any continuous function. "
      ]
    }
  ]
}