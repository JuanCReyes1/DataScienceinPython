{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Part1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanCReyes1/DataScienceinPython/blob/master/A3_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9fjsMehrN3k4"
      },
      "source": [
        "# CSCI 4155/6505 - A3 - To be submitted individually\n",
        "\n",
        "**[Total of 4 points]**\n",
        "\n",
        "For this assignment, you will be modifying the functionality of some base code that implements a convolutional network in PyTorch. Follow along this notebook in Google Colab, running each code block as you go, and insert answers where appropriate.\n",
        "(Optional note: this assignment builds directly on last week's lab where you modified parts of the PyTorch tutorials!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WD81nHOfrEcx",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDbQh7QMrEc3",
        "colab": {}
      },
      "source": [
        "# PyTorch packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# torchvision for loading MNIST dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EM7iYDxkMIps"
      },
      "source": [
        "First, we have to load the MNIST dataset. Try running the code block below, and if it executes successfully, you should see a printout saying that there are 60,000 training examples and 10,000 test examples. A folder titled \"mnist_data\" will appear in your left sidebar if you click on the folder icon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pxCQM2iIrEc7",
        "colab": {},
        "outputId": "b59b4b48-121c-4615-e2c5-371194463daa"
      },
      "source": [
        "# Download the training data\n",
        "train_data = datasets.MNIST('./mnist_data', download=True, train=True,\n",
        "                            transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,))\n",
        "                            ]))\n",
        "\n",
        "# Download the test data\n",
        "test_data = datasets.MNIST('./mnist_data', download=True, train=False,\n",
        "                            transform=transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,))\n",
        "                            ]))\n",
        "\n",
        "classes = [i for i in range(10)]\n",
        "\n",
        "print(\"Training examples: \", len(train_data))\n",
        "print(\"Test examples: \", len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples:  60000\n",
            "Test examples:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iQAh-OPINJeU"
      },
      "source": [
        "For now we will assume that we are using the MNIST dataset. I want to call a single function that encapsulates all parts of the process: initializing the network, training, and testing. Passing to this function as arguments, I want to be able to control some basic functionality of the learning process:\n",
        "\n",
        "*   Number of epochs (repetitions of the entire training data)\n",
        "*   Batch size (how many training examples to average over per gradient update)\n",
        "\n",
        "The function call will look like:\n",
        "\n",
        "```\n",
        "losses, train_acc, test_acc = eval_net(epochs, batch_size)\n",
        "```\n",
        "\n",
        "*   `losses` will be a list of all the losses I saw during training: one for every update.\n",
        "*   `train_acc` will be a single scalar: the accuracy on the training data after training is finished.\n",
        "*   `test_acc` will be a single scalar: the accuracy on the test data after training is finished\n",
        "\n",
        "Below is the implementation of `eval_net()`.\n",
        "\n",
        "(Optional note: If the following code is confusing, please note that this is exactly the same as what you already went through step-by-step in last week's lab, so you may need to review that first.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e1VHebuHrEdC",
        "colab": {}
      },
      "source": [
        "def eval_net(epochs, batch_size):\n",
        "\n",
        "  ##### Prepare return values ##################################################\n",
        "  losses = []\n",
        "  train_acc = 0\n",
        "  test_acc = 0\n",
        "\n",
        "  ##### Create iterators for each dataset ######################################\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  ##### Define the network #####################################################\n",
        "  class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 6, 3)     # 1 channel in, 6 filters out, 3x3 filters\n",
        "      self.pool = nn.MaxPool2d(2, 2)      # 2x2 pooling, with a stride of 2 (move the window by 2 pixels)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 3)    # 6 filters in, 16 filters out, 3x3 filters\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120) # the 16 filtered images are reduced to 5x5 now, connect to 120 hidden units out\n",
        "      self.fc2 = nn.Linear(120, 84)       # 120 hidden units in, 84 hidden units out\n",
        "      self.fc3 = nn.Linear(84, 10)        # 84 hidden units in, 10 outputs units\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5) # .view() is similar to .reshape(), so this flattens x into a vector\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.log_softmax(self.fc3(x), dim=1)\n",
        "      return x\n",
        "  \n",
        "  ##### Initialize the network and optimizer ###################################\n",
        "  print(\"Initializing the network ...\")\n",
        "  net = Net()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # lr = learning rate/step size\n",
        "\n",
        "  ##### Training the network ###################################################\n",
        "  print(\"Training the network ...\")\n",
        "  for e in range(epochs):  # loop over the dataset multiple times\n",
        "    print(\"Epoch: \", e+1)\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      inputs, labels = data\n",
        "      optimizer.zero_grad() # zero the parameter gradients\n",
        "\n",
        "      outputs = net(inputs) # forward pass\n",
        "      loss = criterion(outputs, labels) # compute loss\n",
        "      loss.backward() # backward pass\n",
        "      optimizer.step() # gradient descent update\n",
        "\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  ##### Evaluating the network on training data ################################\n",
        "  print(\"Evaluating on training data ...\")\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "      inputs, labels = data\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  train_acc = correct / total\n",
        "\n",
        "  ##### Evaluating the network on test data ####################################\n",
        "  print(\"Evaluating on test data ...\")\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      inputs, labels = data\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  test_acc = correct / total\n",
        "\n",
        "  return losses, train_acc, test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vcnm1UqkVMQW"
      },
      "source": [
        "Now we can try out our implementation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e9uU7BjzVjq2",
        "colab": {},
        "outputId": "4dc2e7e6-6d7a-4924-e9c8-4988ed17ce08"
      },
      "source": [
        "losses, train_acc, test_acc = eval_net(epochs=2, batch_size=100)\n",
        "print(\"Training accuracy: \", train_acc)\n",
        "print(\"Test accuracy: \", test_acc)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing the network ...\n",
            "Training the network ...\n",
            "Epoch:  1\n",
            "Epoch:  2\n",
            "Evaluating on training data ...\n",
            "Evaluating on test data ...\n",
            "Training accuracy:  0.8521\n",
            "Test accuracy:  0.8607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rxMqVf9cyS3H"
      },
      "source": [
        "# Questions\n",
        "\n",
        "For the following questions, you will mostly be copying and pasting the implementation of `eval_net()` and modifying a few things.\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "a) **[1 point]** You will implement a modification called `eval_net_a()`. Since we are following the implementation in `eval_net()`, assume that there are always 2 convolutional layers, and 2 fully connected hidden layers (the layer of size 10 is the output). We want to control the number of filters and the size of the hidden layers. As arguments, we will pass the epoch and batch_size as before, but also pass a list containing 4 elements: \n",
        "\n",
        "*   The number of filters in convolutional layer 1\n",
        "*   The number of filters in convolutional layer 2\n",
        "*   The number of hidden nodes in fully connected layer 1\n",
        "*   The number of hidden nodes in fully connected layer 2\n",
        "\n",
        "```\n",
        "num_params = [num_filters1, num_filters2, num_hidden1, num_hidden2]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_BIKWtRtdzET",
        "colab": {}
      },
      "source": [
        "def eval_net_a(epochs, batch_size, num_params):\n",
        "  # Insert your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iU-u4Ar0eUFC",
        "colab": {}
      },
      "source": [
        "# We will call your answer like this:\n",
        "losses, train_acc, test_acc = eval_net_a(epochs=2, batch_size=100, num_params=[6, 16, 120, 84])\n",
        "print(\"Training accuracy: \", train_acc)\n",
        "print(\"Test accuracy: \", test_acc)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LzFm3vGLgpAo"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "b) **[1 point]** You will implement a modification called `eval_net_b()`. **Remove the second convolutional layer from `eval_net()`.** Now there should only be 1 convolutional layer, followed by 1 pooling layer, and 2 fully connected hidden layers. The convolutional filters are currently 3x3 and the pooling is currently 2x2. We will keep these square, but we want to control the size of the filters and the size of the pooling layer. We will add a new argument that controls these:\n",
        "\n",
        "```\n",
        "sizes = [filter_size, pooling_size]\n",
        "```\n",
        "\n",
        "**Be warned:** by modifying the filter sizes, you will also have to modify the total number of inputs into the first hidden layer. It was hard-coded at `16*5*5`, because we figured out that the images were reduced to 5x5 images after the convolution and pooling, but this will no longer be true. **Hint: use `x.size()` to get the proper dimensions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_2gOfvYlilnO",
        "colab": {}
      },
      "source": [
        "def eval_net_b(epochs, batch_size, sizes):\n",
        "  # Insert your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e46COLiIin9i",
        "colab": {}
      },
      "source": [
        "# We will call your answer like this:\n",
        "losses, train_acc, test_acc = eval_net_b(epochs=2, batch_size=100, sizes=[3, 2])\n",
        "print(\"Training accuracy: \", train_acc)\n",
        "print(\"Test accuracy: \", test_acc)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yl44Ykwmjmzq"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "c) **[1 point]** You will implement a modification called `eval_net_c()`. The original `eval_net()` uses ReLU activations in the hidden layers. We should also try different activation functions. **Find a new activation function in the torch.nn.functional documentation.** They are listed under \"Non-linear activation functions\".\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.functional.html\n",
        "\n",
        "Replace the ReLU activations with your new activation function. Many of these take additional arguments. Feel free to try out different values for these parameters.\n",
        "\n",
        "**Also find a new pooling function.** These can be found at:\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "listed under \"Pooling layers\". Be sure to pick one with the \"2d\" suffix. Currently we are using MaxPool2d. Replace it with the pooling function that you find."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zWdzEU2GlCWk",
        "colab": {}
      },
      "source": [
        "def eval_net_c(epochs, batch_size):\n",
        "  # Insert your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8rE0geaZlF6Y",
        "colab": {}
      },
      "source": [
        "# We will call your answer like this:\n",
        "losses, train_acc, test_acc = eval_net_c(epochs=2, batch_size=100)\n",
        "print(\"Training accuracy: \", train_acc)\n",
        "print(\"Test accuracy: \", test_acc)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MqS5mJpG1kOz"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "d) **[1 point]** You will implement a modification called `eval_net_d()`. During training, we use backpropagation to compute the gradient of the weights when we call:\n",
        "\n",
        "`loss.backward()`\n",
        "\n",
        "Then we use the gradient to update the weights in the step:\n",
        "\n",
        "`optimizer.step()`\n",
        "\n",
        "The exact formula used to update the weights depends on which optimizer we chose. In `eval_net()`, we are using Stochastic Gradient Descent (SGD), with momentum. There are many optimizers, some of which can be found at:\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "**Find a new optimization algorithm under \"Algorithms\" and replace the optimizer in `eval_net()` with it.** Some algorithms include Adadelta, Adagrad, Adam, and RMSProp. Some of them require additional parameters. Feel free to use the defaults, or try out different values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wvkJPR_N2_yJ",
        "colab": {}
      },
      "source": [
        "def eval_net_d(epochs, batch_size):\n",
        "  # Insert your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ct0mSBvG3Ge1",
        "colab": {}
      },
      "source": [
        "# We will call your answer like this:\n",
        "losses, train_acc, test_acc = eval_net_d(epochs=2, batch_size=100)\n",
        "print(\"Training accuracy: \", train_acc)\n",
        "print(\"Test accuracy: \", test_acc)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}